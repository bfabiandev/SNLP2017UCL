{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\bar}{\\,|\\,}\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\weights}{\\mathbf{w}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the last assignment, you will apply deep learning methods to solve a particular story understanding problem. Automatic understanding of stories is an important task in natural language understanding [[1]](http://anthology.aclweb.org/D/D13/D13-1020.pdf). Specifically, you will develop a model that given a sequence of sentences learns to sort these sentence in order to yield a coherent story [[2]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/short-commonsense-stories.pdf). This sounds (and to an extent is) trivial for humans, however it is quite a difficult task for machines as it involves commonsense knowledge and temporal understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "You are given a dataset of 45502 instances, each consisting of 5 sentences. Your system needs to ouput a sequence of numbers which represent the predicted order of these sentences. For example, given a story:\n",
    "\n",
    "    He went to the store.\n",
    "    He found a lamp he liked.\n",
    "    He bought the lamp.\n",
    "    Jan decided to get a new lamp.\n",
    "    Jan's lamp broke.\n",
    "\n",
    "your system needs to provide an answer in the following form:\n",
    "\n",
    "    2\t3\t4\t1\t0\n",
    "\n",
    "where the numbers correspond to the zero-based index of each sentence in the correctly ordered story. So \"`2`\" for \"`He went to the store.`\" means that this sentence should come 3rd in the correctly ordered target story. In this particular example, this order of indices corresponds to the following target story:\n",
    "\n",
    "    Jan's lamp broke.\n",
    "    Jan decided to get a new lamp.\n",
    "    He went to the store.\n",
    "    He found a lamp he liked.\n",
    "    He bought the lamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "To develop your model(s), we provide a training and a development datasets. The test dataset will be held out, and we will use it to evaluate your models. The test set is coming from the same task distribution, and you don't need to expect drastic changes in it.\n",
    "\n",
    "You will use [TensorFlow](https://www.tensorflow.org/) to build a deep learning model for the task. We provide a very crude system which solves the task with a low accuracy, and a set of additional functions you will have to use to save and load the model you create so that we can run it.\n",
    "\n",
    "As we have to run the notebooks of each submission, and as deep learning models take long time to train, your notebook **NEEDS** to conform to the following requirements:\n",
    "* You **NEED** to run your parameter optimisation offline, and provide your final model saved by using the provided function\n",
    "* The maximum size of a zip file you can upload to moodle is 160MB. We will **NOT** allow submissions larger than that.\n",
    "* We do not have time to train your models from scratch! You **NEED** to provide the full code you used for the training of your model, but by all means you **CANNOT** call the training method in the notebook you will send to us.\n",
    "* We will run these notebooks automatically. If your notebook runs the training procedure, in addition to loading the model, and we need to edit your code to stop the training, you will be penalised with **-20 points**.\n",
    "* If you do not provide a pretrained model, and rely on training your model on our machines, you will get **0 points**.\n",
    "* Your submissions will be tested on the stat-nlp-book Docker image to ensure that it does not have any dependencies outside of those that we provide. If your submission fails to adhere to this requirement, you will get **0 points**.\n",
    "\n",
    "Running time and memory issues:\n",
    "* We have tested a possible solution on a mid-2014 MacBook Pro, and a few epochs of the model run in less than 3min. Thus it is possible to train a model on the data in reasonable time. However, be aware that you will need to run these models many times over, for a larger number of epochs (more elaborate models, trained on much larger datasets can train for weeks! However, this shouldn't be the case here.). If you find training times too long for your development cycle you can reduce the training set size. Once you have found a good solution you can increase the size again. Caveat: model parameters tuned on a smaller dataset may not be optimal for a larger training set.\n",
    "* In addition to this, as your submission is capped by size, feel free to experiment with different model sizes, numeric values of different precisions, filtering the vocabulary size, downscaling some vectors, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "A non-exhaustive list of things you might want to give a try:\n",
    "- better tokenization\n",
    "- experiment with pre-trained word representations such as [word2vec](https://code.google.com/archive/p/word2vec/), or [GloVe](http://nlp.stanford.edu/projects/glove/). Be aware that these representations might take a lot of parameters in your model. Be sure you use only the words you expect in the training/dev set and account for OOV words. When saving the model parameters, pre-rained word embeddings can simply be used in the word embedding matrix of your model. As said, make sure that this word embedding matrix does not contain all of word2vec or GloVe. Your submission is limited, and we will not allow uploading nor using the whole representations set (up to 3GB!)\n",
    "- reduced sizes of word representations\n",
    "- bucketing and batching (our implementation is deliberately not a good one!)\n",
    "  - make sure to draw random batches from the data! (we do not provide this in our code!)\n",
    "- better models:\n",
    "  - stacked RNNs (see tf.contrib.rnn.MultiRNNCell)\n",
    "  - bi-directional RNNs\n",
    "  - attention\n",
    "  - word-by-word attention\n",
    "  - conditional encoding\n",
    "  - get model inspirations from papers on [nlp.stanford.edu/projects/snli/](nlp.stanford.edu/projects/snli/)\n",
    "  - sequence-to-sequence encoder-decode architecture for producing the right ordering\n",
    "- better training procedure:\n",
    "  - different training algorithms\n",
    "  - dropout on the input and output embeddings (see tf.nn.dropout)\n",
    "  - L2 regularization (see tf.nn.l2_loss)\n",
    "  - gradient clipping (see tf.clip_by_value or tf.clip_by_norm)\n",
    "- model selection:\n",
    "  - early stopping\n",
    "- hyper-parameter optimization (e.g. random search or grid search (expensive!))\n",
    "    - initial learning rate\n",
    "    - dropout probability\n",
    "    - input and output size\n",
    "    - L2 regularization\n",
    "    - gradient clipping value\n",
    "    - batch size\n",
    "    - ...\n",
    "- post-processing\n",
    "  - for incorporating consistency constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "It is important that this file is placed in the **correct directory**. It will not run otherwise. The correct directory is\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2017/assignment3/problem/group_X/\n",
    "    \n",
    "where `DIRECTORY_OF_YOUR_BOOK` is a placeholder for the directory you downloaded the book to, and in `X` in `group_X` contains the number of your group.\n",
    "\n",
    "After you placed it there, **rename the notebook file** to `group_X.ipynb`.\n",
    "\n",
    "The notebook is pre-set to save models in\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2017/assignment3/problem/group_X/model/\n",
    "\n",
    "Be sure not to tinker with that directory - we expect your submission to contain a `model` subdirectory with a single saved model! \n",
    "The saving procedure might overwrite the latest save, or not. Make sure you understand what it does, and upload only a single model! (for more details check tf.train.Saver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "This notebook will be used by you to provide your solution, and by us to both assess your solution and enter your marks. It contains three types of sections:\n",
    "\n",
    "1. **Setup** Sections: these sections set up code and resources for assessment. **Do not edit, move nor copy these cells**.\n",
    "2. **Assessment** Sections: these sections are used for both evaluating the output of your code, and for markers to enter their marks. **Do not edit, move, nor copy these cells**.\n",
    "3. **Task** Sections: these sections require your solutions. They may contain stub code, and you are expected to edit this code. For free text answers simply edit the markdown field.  \n",
    "\n",
    "**If you edit, move or copy any of the setup, assessments and mark cells, you will be penalised with -20 points**.\n",
    "\n",
    "Note that you are free to **create additional notebook cells** within a task section. \n",
    "\n",
    "Please **do not share** this assignment nor the dataset publicly, by uploading it online, emailing it to friends etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit your solution:\n",
    "\n",
    "* Make sure that your solution is fully contained in this notebook. Make sure you do not use any additional files other than your saved model.\n",
    "* Make sure that your solution runs linearly from start to end (no execution hops). We will run your notebook in that order.\n",
    "* **Before you submit, make sure your submission is tested on the stat-nlp-book Docker setup to ensure that it does not have any dependencies outside of those that we provide. If your submission fails to adhere to this requirement, you will get 0 points**.\n",
    "* **If running your notebook produces a trivially fixable error that we spot, we will correct it and penalise you with -20 points. Otherwise you will get 0 points for that solution.**\n",
    "* **Rename this notebook to your `group_X`** (where `X` is the number of your group), and adhere to the directory structure requirements, if you have not already done so. ** Failure to do so will result in -1 point.**\n",
    "* Download the notebook in Jupyter via *File -> Download as -> Notebook (.ipynb)*.\n",
    "* Your submission should be a zip file containing the `group_X` directory, containing `group_X.ipynb` notebook, and the `model` directory with the saved model\n",
    "* Upload that file to the Moodle submission site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change, move or copy it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:56.249298",
     "start_time": "2016-12-20T12:04:54.376398"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#! SETUP 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../../\"\n",
    "sys.path.append(_snlp_book_dir)\n",
    "# docker image contains tensorflow 0.10.0rc0. We will support execution of only that version!\n",
    "import statnlpbook.nn as nn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Training Data\n",
    "\n",
    "This cell loads the training data. **Do not edit the next cell, nor copy/duplicate it**. Instead refer to the variables in your own code, and slice and dice them as you see fit (but do not change their values). \n",
    "For example, no one stops you from introducing, in the corresponding task section, `my_train` and `my_dev` variables that split the data into different folds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:57.110195",
     "start_time": "2016-12-20T12:04:56.251082"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#! SETUP 2 - DO NOT CHANGE, MOVE NOR COPY\n",
    "data_path = _snlp_book_dir + \"data/nn/\"\n",
    "data_train = nn.load_corpus(data_path + \"train.tsv\")\n",
    "data_dev = nn.load_corpus(data_path + \"dev.tsv\")\n",
    "assert(len(data_train) == 45502)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures\n",
    "\n",
    "Notice that the data is loaded from tab-separated files. The files are easy to read, and we provide the loading functions that load it into a simple data structure. Feel free to check details of the loading.\n",
    "\n",
    "The data structure at hand is an array of dictionaries, each containing a `story` and the `order` entry. `story` is a list of strings, and `order` is a list of integer indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:57.134033",
     "start_time": "2016-12-20T12:04:57.115270"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order': [3, 2, 1, 0, 4],\n",
       " 'story': ['His parents understood and decided to make a change.',\n",
       "  'The doctors told his parents it was unhealthy.',\n",
       "  'Dan was overweight as well.',\n",
       "  \"Dan's parents were overweight.\",\n",
       "  'They got themselves and Dan on a diet.']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Model implementation\n",
    "\n",
    "Your primary task in this assignment is to implement a model that produces the right order of the sentences in the dataset.\n",
    "\n",
    "### Preprocessing pipeline\n",
    "\n",
    "First, we construct a preprocessing pipeline, in our case `pipeline` function which takes care of:\n",
    "- out-of-vocabulary words\n",
    "- building a vocabulary (on the train set), and applying the same unaltered vocabulary on other sets (dev and test)\n",
    "- making sure that the length of input is the same for the train and dev/test sets (for fixed-sized models)\n",
    "\n",
    "You are free (and encouraged!) to do your own input processing function. Should you experiment with recurrent neural networks, you will find that you will need to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to make sure that the `pipeline` function returns the necessary data for your computational graph feed - the required inputs in this case, as we will call this function to process your dev and test data. If you do not make sure that the same pipeline applied to the train set is applied to other datasets, your model may not work with that data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take a look at the result of the `pipeline` with the `show_data_instance` function to make sure that your data loaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "import statnlpbook.util as util\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "PAD_TOKEN = '<PAD>'\n",
    "OOV_TOKEN = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############        Utilities API         #################\n",
    "#  Any generic utility functions should go here\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enables tensorboard to visualize the graph later\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = bytes(\"<stripped %d bytes>\"%size, 'utf-8')\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleSave(dictionary, output_name):\n",
    "    pickle_out = open(\"{}.pickle\".format(output_name),\"wb\")\n",
    "    pickle.dump(dictionary, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleLoad(file_name):\n",
    "    return pickle.load( open( file_name, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndDumpCSV(txtfile,output_name,save=True):\n",
    "    ''''\n",
    "    Read a txt file in csv format (tested with glove) and save a python dictionary of the embeddings using pickle\n",
    "    Also return said dictionary\n",
    "    '''\n",
    "    mydict = {}\n",
    "    with open(txtfile,'r') as f:\n",
    "        for line in f:\n",
    "            mydict[line.split(' ')[0]] = np.array([float(n) for n in line.split(' ')[1:]])\n",
    "        if(save):\n",
    "                pickle_out = open(\"{}.pickle\".format(output_name),\"wb\")\n",
    "                pickle.dump(mydict, pickle_out)\n",
    "                pickle_out.close()\n",
    "        else:\n",
    "            return mydict            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayDict(dictionary, num_vals):\n",
    "    '''\n",
    "    Display the first num_vals entries of a dictionary\n",
    "    '''\n",
    "    count = 0\n",
    "    for key,val in dictionary.items():\n",
    "        if(count>num_vals):\n",
    "            return\n",
    "        print(\"key : {} , val : \\n {} and the datatypes are: \\n key -> {} and val -> {}\\n\".format(key,val,type(key) ,type(val)))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopper class:\n",
    "# Logic:\n",
    "#  After each epoch of training, compare the dev accuracy with the max dev accuracy  achieved\n",
    "#  If it is bigger, replace it, save the model, reset the decreasing accuracy count and continue\n",
    "#  If it is smaller, \n",
    "#    Check whether the patience count is equal to teh number of consecutive decreasing accuracies\n",
    "#       if yes:  Trigger early stopping (Flag to break off the training loop)\n",
    "#       if no : add 1 to the count of consecutive decreasing accuracies and continue\n",
    "#  After training, the model saved needs to be reloaded, as this will be the last model where the accuracy increased\n",
    "\n",
    "class EarlyStopper(object):\n",
    "    '''\n",
    "    Early stopper class: after each epoch of training assess whether the accuracy on the dev-set is smaller\n",
    "    than the accuracy on the dev set on the previous epoch.\n",
    "    If this is not the case for a patience number of epochs, stop the training and keep the model of the last\n",
    "    epoch where the accuracy increased\n",
    "    '''\n",
    "    def __init__(self, patience, verbose):\n",
    "        '''\n",
    "        patience : after how many epochs of decreasing dev accuracy do we stop\n",
    "        '''\n",
    "        self.patience = patience\n",
    "        self.decreasing_epochs = 0\n",
    "        self.last_increasing_accuracy = 0.0\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def checkEarlyStopping(self,dev_accuracy, session):\n",
    "        \n",
    "        if(dev_accuracy > self.last_increasing_accuracy):\n",
    "            if(self.verbose):\n",
    "                print(\"Accuracy Increasing in the dev set, saving the model!\")\n",
    "            nn.save_model(session)\n",
    "            self.last_increasing_accuracy = dev_accuracy \n",
    "            self.decreasing_epochs = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.decreasing_epochs+=1\n",
    "            if(self.decreasing_epochs >= self.patience):\n",
    "                print(\"Early stopping activated : {} consecutive epochs where accuracy is decresing!\".format(self.decreasing_epochs))\n",
    "                print(\"Model saved yields a dev set accuracy of : {}\".format(self.last_increasing_accuracy))\n",
    "                return True\n",
    "            else:\n",
    "                if(self.verbose):\n",
    "                    print(\"Accuracy decreasing on the Dev set, taking note and continuing!\")\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWord(token,vocab):\n",
    "    for key,item in vocab.items():\n",
    "        if (token == item):\n",
    "            return key\n",
    "    raise ValueError(\"Word in phrase not in the vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############        Utilities API  END       #################\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############        ERROR ANALYSIS API       ###############\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(data, predictions):\n",
    "    confusion = defaultdict(int)\n",
    "    for y_true, y_guess in zip(data, predictions):\n",
    "        for order_true , order_guess in zip(y_true,y_guess):\n",
    "            confusion[(order_true, order_guess)] += 1\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix_for_sentence(data,predictions,sentence):\n",
    "    confusion = defaultdict(int)\n",
    "    for y_true, y_guess in zip(data, predictions):\n",
    "        confusion[(y_true[sentence], y_guess[sentence])] += 1\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getErrors(data, true_orders, predicted_orders):\n",
    "    errorsList = []\n",
    "    list_index = 0\n",
    "    for order_true, order_guess in zip(true_orders, predicted_orders):\n",
    "        if (not np.all(order_true == order_guess)):\n",
    "            story = data[list_index]['story']\n",
    "            true_paragraph = [None]*5\n",
    "            count =0\n",
    "            for i in order_true:\n",
    "                true_paragraph[i]=story[count]\n",
    "                count +=1\n",
    "            \n",
    "            predicted_paragraph =[None]*5\n",
    "            count =0\n",
    "            for i in order_guess:\n",
    "                predicted_paragraph[i]=story[count]\n",
    "                count+=1\n",
    "                \n",
    "            error = {\"index\": list_index,\n",
    "                     \"true_order\": order_true,\n",
    "                     'predicted_order':order_guess,\n",
    "                    'true_paragraph':true_paragraph,\n",
    "                    'predicted_paragraph':predicted_paragraph}\n",
    "            errorsList.append(error)\n",
    "        list_index+=1\n",
    "    return errorsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayErrors(errorsList, numToDisp):\n",
    "    for error in errorsList[:numToDisp]:\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        print(\"### The correct order is : ###\")\n",
    "\n",
    "        for phrase in error[\"true_paragraph\"]:\n",
    "            print(phrase)\n",
    "        \n",
    "        print(\"\\n ### The predicted order was : ###\")\n",
    "        for phrase in error[\"predicted_paragraph\"]:\n",
    "            print(phrase)\n",
    "        print(\"---------------------------------------------------------------------------- \\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPADandOOVHistogramsOnErrors(errors,stories):\n",
    "    stats = {}\n",
    "    stats['PAD_hist'] = defaultdict(float)\n",
    "    stats['OOV_hist'] = defaultdict(float)\n",
    "    for error in errors:\n",
    "        phrase_index = 0 \n",
    "        for true_pos,pred_pos in zip(error['true_order'],error['predicted_order']):\n",
    "            if(true_pos != pred_pos):\n",
    "                story_index = error['index']\n",
    "                phrase = stories[story_index][phrase_index]\n",
    "                pad_nb = np.count_nonzero(phrase==0)\n",
    "                oov_nb = np.count_nonzero(phrase==1)\n",
    "                stats['PAD_hist'][pad_nb]+=1.0\n",
    "                stats['OOV_hist'][oov_nb]+=1.0\n",
    "            phrase_index+=1\n",
    "        \n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(stats,interest,sorting_param=0):\n",
    "    \n",
    "    values =[]\n",
    "    labels = []\n",
    "    \n",
    "    histItems =[]\n",
    "    for key,value in stats[interest].items():\n",
    "        histItems.append((key,value))\n",
    "    \n",
    "    histItems = sorted(histItems, key=lambda x: x[sorting_param])\n",
    "   \n",
    "    for key,value in histItems:\n",
    "        labels.append(key)\n",
    "        values.append(value)\n",
    "        \n",
    "    util.plot_bar_graph(values, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFullPadandOOVHistorgrams(stories):\n",
    "    stats = {}\n",
    "    stats['PAD_hist'] = defaultdict(float)\n",
    "    stats['OOV_hist'] = defaultdict(float)\n",
    "    for story in stories:\n",
    "        for phrase in story:\n",
    "            pad_nb = np.count_nonzero(phrase==0)\n",
    "            oov_nb = np.count_nonzero(phrase==1)\n",
    "            stats['PAD_hist'][pad_nb]+=1.0\n",
    "            stats['OOV_hist'][oov_nb]+=1.0\n",
    "\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getErrorWordFrequency(errors,stories,vocab):\n",
    "    word_frequency = defaultdict(float)\n",
    "    for error in errors:\n",
    "        phrase_index = 0 \n",
    "        for true_pos,pred_pos in zip(error['true_order'],error['predicted_order']):\n",
    "            if(true_pos != pred_pos):\n",
    "                story_index = error['index']\n",
    "                phrase = stories[story_index][phrase_index]\n",
    "                for word in phrase:\n",
    "                    word_str = findWord(word,vocab)\n",
    "                    word_frequency[word_str]+=1.0\n",
    "        \n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_histogram(word_freq,num_displayed,values_ignored):\n",
    "    \n",
    "    values =[]\n",
    "    labels = []\n",
    "    \n",
    "    histItems =[]\n",
    "    count = 0\n",
    "    for key,value in word_freq.items():\n",
    "        if(count>=num_displayed):\n",
    "            break\n",
    "        if(key not in values_ignored):\n",
    "            histItems.append((key,value))\n",
    "            count+=1\n",
    "    \n",
    "    histItems = sorted(histItems, key=lambda x: -x[1])\n",
    "   \n",
    "    for key,value in histItems:\n",
    "        labels.append(key)\n",
    "        values.append(value)\n",
    "        \n",
    "    util.plot_bar_graph(values, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordFrequency(stories,vocab):\n",
    "    word_frequency = defaultdict(float)\n",
    "    for story in stories:\n",
    "        for phrase in story:\n",
    "            for word in phrase:\n",
    "                word_str = findWord(word,vocab)\n",
    "                word_frequency[word_str]+=1.0\n",
    "        \n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_ratios(standard_freq,error_freq):\n",
    "    freq_ratio = defaultdict(float)\n",
    "    for word in error_freq.keys():\n",
    "        freq_ratio[word] = error_freq[word]/standard_freq[word]\n",
    "    return freq_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "############           ERROR ANALYSIS API END    ###############\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############           PREPOCESSING API         ######################\n",
    "#  Here will go all the functions relating to preprocessing\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create tokenizer so it handles the following:\n",
    "# - (n't 's 'm 're 've 'll 'd) word endings to be separated (shouldn't -> (should, n't))\n",
    "# - punctuation at the end of sentences (This is a sentence. -> (..., a, sentence, .))\n",
    "#     - try to make sure if possible to filter out only sentence ending punctuation (U.S. etc. Mr. St.) should be kept\n",
    "#     - also words like e.g. a.m. p.m.\n",
    "# - separate numbers from others ($5 -> $, 5)\n",
    "#\n",
    "# OR find a library that is included in the docker image (nltk and spacy aren't...) that does that for us\n",
    "#\n",
    "# decide what to do with words not in GloVe (random embedding?)\n",
    "\n",
    "# tokenisation\n",
    "punctuation = '.,:;?!\"'\n",
    "endings_2 = [\"'s\", \"'m\", \"'d\"]\n",
    "endings_3 = [\"n't\", \"'re\", \"'ve\", \"'ll\"]\n",
    "valid_words = ['e.g.', 'a.m.', 'p.m.', 'U.S.', 'etc.', 'i.e.', 'Mr.', 'Mrs.', 'Ms.', 'St.']\n",
    "currency = '$€£'\n",
    "\n",
    "def tokenize_word(word):    \n",
    "    if len(word) == 1:\n",
    "        return [word]\n",
    "    \n",
    "    if word.isalpha():\n",
    "        return [word]\n",
    "\n",
    "    if word in valid_words:\n",
    "        return [word]\n",
    "    \n",
    "    if word[0] in currency or word[0] in punctuation:\n",
    "        tokens = tokenize_word(word[1:])\n",
    "        sign = word[0]\n",
    "        tokens.insert(0, sign)\n",
    "        return tokens\n",
    "    \n",
    "    if word[-1] in punctuation:\n",
    "        tokens = tokenize_word(word[:-1])\n",
    "        tokens.append(word[-1])\n",
    "        return tokens\n",
    "    \n",
    "    if len(word) > 2 and word[-2:] in endings_2:\n",
    "        tokens = tokenize_word(word[:-2])\n",
    "        tokens.append(word[-2:])\n",
    "        return tokens\n",
    "    \n",
    "    if len(word) > 3 and word[-3:] in endings_3:\n",
    "        tokens = tokenize_word(word[:-3])\n",
    "        tokens.append(word[-3:])\n",
    "        return tokens\n",
    "    \n",
    "    return [word]\n",
    "        \n",
    "def tokenize_sent(sent):\n",
    "    sent = sent.split(' ')\n",
    "    ret = [tokens for word in sent if len(word) > 0 for tokens in tokenize_word(word) ]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing pipeline, used to load the data intro a structure required by the model\n",
    "def pipeline(data, vocab=None, max_sent_len_=None):\n",
    "    is_ext_vocab = True\n",
    "    if vocab is None:\n",
    "        is_ext_vocab = False\n",
    "        vocab = {'<PAD>': 0, '<OOV>': 1}\n",
    "    \n",
    "    if is_ext_vocab:\n",
    "        if 'The' in vocab:\n",
    "            capitalized = True\n",
    "        else:\n",
    "            capitalized = False\n",
    "    else:\n",
    "        capitalized = True\n",
    "\n",
    "    max_sent_len = -1\n",
    "    data_sentences = []\n",
    "    data_orders = []\n",
    "    for instance in data:\n",
    "        sents = []\n",
    "        for sentence in instance['story']:\n",
    "            sent = []\n",
    "            tokenized = tokenize_sent(sentence)\n",
    "            for token in tokenized:\n",
    "                # if we do not use capitalized letters, make the word lowercase\n",
    "                if not capitalized:\n",
    "                    token = token.lower()\n",
    "                \n",
    "                if not is_ext_vocab and token not in vocab:\n",
    "                    vocab[token] = len(vocab)\n",
    "                if token not in vocab:\n",
    "                    token_id = vocab['<OOV>']\n",
    "                    #print('NOT IN VOCAB: ' + token)\n",
    "                else:\n",
    "                    token_id = vocab[token]\n",
    "                sent.append(token_id)\n",
    "            if len(sent) > max_sent_len:\n",
    "                max_sent_len = len(sent)\n",
    "            sents.append(sent)\n",
    "        data_sentences.append(sents)\n",
    "        data_orders.append(instance['order'])\n",
    "\n",
    "    if max_sent_len_ is not None:\n",
    "        max_sent_len = max_sent_len_\n",
    "    out_sentences = np.full([len(data_sentences), 5, max_sent_len], vocab['<PAD>'], dtype=np.int32)\n",
    "\n",
    "    for i, elem in enumerate(data_sentences):\n",
    "        for j, sent in enumerate(elem):\n",
    "            out_sentences[i, j, 0:len(sent)] = sent\n",
    "\n",
    "    out_orders = np.array(data_orders, dtype=np.int32)\n",
    "    \n",
    "    return out_sentences, out_orders, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:59.842961",
     "start_time": "2016-12-20T12:04:57.136946"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def findMeanEmbedding(embeddingDict):\n",
    "    '''Get the mean embedding and the standard deviation (dimention-wise) from an input embedding dictionary'''\n",
    "    vectorList = list(embeddingDict.values())\n",
    "    return np.mean(vectorList,axis=0), np.std(vectorList,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "####      REMARK    ######\n",
    "#By taking embeddings from glove that are not in the give vocab, aren't we effectively \n",
    "# increasing the length our vocab?????? Because a word not in the vocab that is in the test set will have an \n",
    "# embedding ...\n",
    "\n",
    "# So we have two ways of doing this\n",
    "\n",
    "\n",
    "\n",
    "#1 :\n",
    "# Get the N Most popular words in GLOVE to define our VOCAB and embeddings\n",
    "# Which means that the OOV words in the test set will be the words that are not in the N most popular words\n",
    "# AND all the words that we give a vector for have meaning (are not random)!\n",
    "\n",
    "#Then all we need to do is make a tokensation that makes sure to match what the GLOVE tokenisation is to avoid \n",
    "#missmatches .\n",
    "\n",
    "\n",
    "\n",
    "# 2 :\n",
    "# Using the training set to get a vocab\n",
    "# finding the embeddings in glove for the words in our vocab\n",
    "# FOR the words in our vocab THAT DONT have a glove embedding we give a RANDOM value\n",
    "\n",
    "#Then we are using our vocab to figure out what the oovs are in the test set\n",
    "#We then extract our embedding which is either the GLOVE value of the word or a RANDOM value\n",
    "# and use that  for our LSTM\n",
    "\n",
    "\n",
    "\n",
    "# 1 seems conceptually better to me, but i implemented both we can try, script 1 below  is method 1 and script 2\n",
    "# is method 2\n",
    "\n",
    "\n",
    "## THIS IS ILLUSTRATED IN THE TWO PREPROCESSING SCRIPTS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:59.925263",
     "start_time": "2016-12-20T12:04:59.844598"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Used in 2. in the remark above\n",
    "def createWordEmbeddings(pre_learned_embeddings,total_size = -1):\n",
    "    '''\n",
    "    Using a pre-trained word embeddings dictionary, create our (reduced in size) dictionary of embeddings.\n",
    "    Make sure that all the words in our vocab are embedded, and also use the embeddings of the most popular words,\n",
    "    as long as the total_size of the dictionary is not exceeded.\n",
    "    pre_learned_embeddings : Dictionnary of word embeddings, can come from glove or word2vec\n",
    "    total_size : Length of our output embeddings dictionary\n",
    "    Returns : A dictionary of word embeddings\n",
    "    '''\n",
    "    \n",
    "    if(total_size >=len(pre_learned_embeddings)):\n",
    "        #Undefined behaviour in the above case\n",
    "        raise ValueError(\"Total size is too big\")\n",
    "    \n",
    "    #Get the dimention of the embeddings\n",
    "    dim = len(pre_learned_embeddings[\"the\"])\n",
    "    \n",
    "    #Compute the mean vector and std vector for the glove embeddings\n",
    "    mean_glove, std_glove = findMeanEmbedding(pre_learned_embeddings)\n",
    "\n",
    "    #Initialise the embeddings dict\n",
    "    embeddings = {}\n",
    "    \n",
    "    #Iterate over all the words in our vocabulary\n",
    "    for word, word_index in vocab.items():\n",
    "        #Stop if we reach our total desired size : \n",
    "        #Careful : Will this create bugs with non-embedded words? -> Maybe its better not to allow total_size<vocab_size\n",
    "        if( total_size > 0 and len(embeddings) >= total_size):\n",
    "            print(\"Warning: Total size reached before full vocab was embedded\")\n",
    "            break\n",
    "            \n",
    "            \n",
    "        if(word == PAD_TOKEN):\n",
    "            #Set the <PAD> token to 0\n",
    "            embeddings[word_index] = np.zeros(dim)\n",
    "        elif(word == OOV_TOKEN ):\n",
    "            #Initialize the <OOV> token to 1. Update later (c.f. below)\n",
    "            embeddings[word_index] = np.ones(dim)\n",
    "        elif(word in pre_learned_embeddings):\n",
    "            #If the word is in the glove dictionnary, use this embedding\n",
    "            embeddings[word_index] = pre_learned_embeddings[word]\n",
    "        else:\n",
    "            #If not, set its embedding to a random vector with\n",
    "            #mean the average glove embedding and std the std of the glove embeddings\n",
    "            #TODO : think if there is a better way to assign vectors in our vocab that are not in Glove\n",
    "            mean_with_white_noise = mean_glove + np.random.rand(dim)*std_glove\n",
    "            embeddings[word_index] = mean_with_white_noise\n",
    "            \n",
    "            \n",
    "    #Make some more embeddings than the words that are in our vocab:\n",
    "    #Iterate over the glove Word embeddings\n",
    "    if(total_size > 0):\n",
    "        for word, pre_learned_embedding in pre_learned_embeddings.items():\n",
    "            #If we exceed our total desired length, stop\n",
    "            if(len(embeddings) >= total_size):\n",
    "                break\n",
    "\n",
    "            #Add embeddings that are not already there\n",
    "            #For this to make sense we also need to increase our vocabulary.\n",
    "            if(word not in embeddings):\n",
    "                vocab[word] = len(vocab)\n",
    "                embeddings[vocab[word]] = pre_learned_embedding \n",
    "\n",
    "\n",
    "    #Update the OOV embedding : The idea is to set it the average value of the unused Glove embeddings\n",
    "    #To do so set the OOV value to the mean of all glove embeddings - mean of our embeddings \n",
    "    #ALERT : This mean is corrupted by the noise we are adding in the else clause above and by the embeddings\n",
    "    # for the <PAD> and <OOV> tokens -> Not sure if we should care or not\n",
    "    mean_embeddings , std_embeddings = findMeanEmbedding(embeddings)\n",
    "    OOV_value = mean_glove - mean_embeddings\n",
    "    embeddings[vocab[OOV_TOKEN]] = OOV_value\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:59.954655",
     "start_time": "2016-12-20T12:04:59.926701"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Used in 1 in the remark above\n",
    "def createWordVocabAndEmbeddings(pre_learned_embeddings, total_size):  \n",
    "    '''\n",
    "    Use the total_size first embeddings from pre_learned_embeddings as our vocab and embeddings\n",
    "    Assign the mean vector of unused embeddings to get the OOV token embedding\n",
    "    Assign the origin to the PAD token embedding\n",
    "    '''\n",
    "    \n",
    "    if(total_size >=len(pre_learned_embeddings)):\n",
    "        #Undefined behaviour in the above case\n",
    "        raise ValueError(\"Total size is too big\")\n",
    "    \n",
    "    #Get the dimention of the embeddings\n",
    "    dim = len(pre_learned_embeddings[\"the\"])\n",
    "    \n",
    "    #Compute the mean vector and std vector for the glove embeddings\n",
    "    mean_glove, std_glove = findMeanEmbedding(pre_learned_embeddings)\n",
    "\n",
    "    #Initialise the embeddings and vocab dicts\n",
    "    vocab = {PAD_TOKEN:0, OOV_TOKEN:1}\n",
    "    embeddings = {0:np.zeros(dim) , 1:np.ones(dim)}\n",
    "    \n",
    "    #Create the vocab and embeddings by taking the total_size first tokens in glove\n",
    "    for word, pre_learned_embedding in pre_learned_embeddings.items():\n",
    "        if(len(embeddings)>=total_size):\n",
    "            break\n",
    "        vocab[word]=len(vocab)\n",
    "        embeddings[vocab[word]] = pre_learned_embeddings[word]\n",
    "    \n",
    "    \n",
    "    #Update the OOV embedding : The idea is to set it the average value of the unused Glove embeddings\n",
    "    #To do so set the OOV value to the mean of all glove embeddings - mean of our embeddings \n",
    "    mean_embeddings , std_embeddings = findMeanEmbedding(embeddings)\n",
    "    OOV_value = mean_glove - mean_embeddings\n",
    "    embeddings[vocab[OOV_TOKEN]] = OOV_value\n",
    "    \n",
    "    \n",
    "    return vocab, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPCA(embeddings, output_dim):\n",
    "    '''\n",
    "    Perform PCA on a dictionary of embeddings to return the reduced-dimentionality embeddings with output_dim dimention.\n",
    "    '''\n",
    "    #Get a numpy array from the embeddings to perform the PCA\n",
    "    #Get the input dimentions\n",
    "    in_dim = len(embeddings[0])\n",
    "    num_embeddings = len(embeddings)\n",
    "    #initialise the array:\n",
    "    # get a dim*num_of_embeddings np array with all the embeddings\n",
    "    emb = np.zeros((num_embeddings,in_dim))\n",
    "\n",
    "    #Transfer the embeddings dictionary to the emb array\n",
    "    for k,v in embeddings.items():\n",
    "        emb[k,:] = v\n",
    "\n",
    "\n",
    "    #Perfom PCA using scikit learn\n",
    "    pca = PCA(n_components = output_dim)\n",
    "    pca_embeddings = pca.fit_transform(emb)\n",
    "\n",
    "\n",
    "    #Put the pca-reduced embeddings back into a dictionary\n",
    "    pca_embeddings_dict = {}\n",
    "    count = 0\n",
    "    for embedding in pca_embeddings:\n",
    "        pca_embeddings_dict[count] = embedding\n",
    "        count+=1\n",
    "\n",
    "    #Map the embedding for <PAD> back to 0.\n",
    "    pca_embeddings_dict[0]=np.zeros(pca_embeddings_dict[1].shape)\n",
    "\n",
    "    return pca_embeddings_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############      PREPROCESSING API END    #####################\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############      DO PREPROCESSING           ####################\n",
    "#  In this section put the scripts utilising the functions above to run the pre-processing\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ONLY NEED TO  (AND SHOULD) RUN ONCE: - already on github so not even ###\n",
    "#Save the glove embeddings into a pickle format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readAndDumpCSV(\"./glove/glove.6B.50d.txt\",\"glove6B50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readAndDumpCSV(\"./glove/glove.6B.100d.txt\",\"glove6B100D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readAndDumpCSV(\"./glove/glove.6B.200d.txt\",\"glove6B200D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readAndDumpCSV(\"./glove/glove.6B.300d.txt\",\"glove6B300D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readAndDumpCSV(\"./glove/glove.42B.300d.txt\",\"glove42B300D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computer runs out of memory with this one.....\n",
    "#readAndDumpCSV(\"./glove/glove.840B.300d.txt\" ,\"glove840B300D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Script hyper parameters!! ###\n",
    "\n",
    "#Flags\n",
    "use_pca = False \n",
    "\n",
    "#parameters\n",
    "output_dimention_from_pca = 50\n",
    "embeddings_file_to_load = \"glove6B200D.pickle\"\n",
    "vocab_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'########   Script 1 :   ##########\\n# Use Glove to define the vocab, and (later on, within the model) train with OOV tokens if need be\\n\\n# LOAD the Pickle file of pre-trained embeddings : Choose favorite\\npre_learned_embeddings = pickleLoad(embeddings_file_to_load)\\n\\n#Create the vocab and embeddings of desired size\\nvocab, embeddings = createWordVocabAndEmbeddings(pre_learned_embeddings, vocab_size)\\n\\nif(use_pca):\\n    embeddings = doPCA(embeddings,output_dimention_from_pca)\\n\\n\\n#Get the training data\\ntrain_stories, train_orders, _ = pipeline(data_train, vocab)\\n\\n# get the length of the longest sentence\\nmax_sent_len = train_stories.shape[2]\\n\\n#Get validation data\\ndev_stories, dev_orders, _ = pipeline(data_dev, vocab=vocab, max_sent_len_=max_sent_len)\\n\\npickleSave(vocab, \"VocabScript1\")\\npickleSave(embeddings, \"EmbeddingScript1\")\\n\\n#################################\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''########   Script 1 :   ##########\n",
    "# Use Glove to define the vocab, and (later on, within the model) train with OOV tokens if need be\n",
    "\n",
    "# LOAD the Pickle file of pre-trained embeddings : Choose favorite\n",
    "pre_learned_embeddings = pickleLoad(embeddings_file_to_load)\n",
    "\n",
    "#Create the vocab and embeddings of desired size\n",
    "vocab, embeddings = createWordVocabAndEmbeddings(pre_learned_embeddings, vocab_size)\n",
    "\n",
    "if(use_pca):\n",
    "    embeddings = doPCA(embeddings,output_dimention_from_pca)\n",
    "\n",
    "\n",
    "#Get the training data\n",
    "train_stories, train_orders, _ = pipeline(data_train, vocab)\n",
    "\n",
    "# get the length of the longest sentence\n",
    "max_sent_len = train_stories.shape[2]\n",
    "\n",
    "#Get validation data\n",
    "dev_stories, dev_orders, _ = pipeline(data_dev, vocab=vocab, max_sent_len_=max_sent_len)\n",
    "\n",
    "pickleSave(vocab, \"VocabScript1\")\n",
    "pickleSave(embeddings, \"EmbeddingScript1\")\n",
    "\n",
    "#################################\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing version of Script 1 #### \n",
    "# Use this in order to load the vocab and embeddings produced and only load them directly when needed\n",
    "vocab = pickleLoad(\"VocabScript1.pickle\")\n",
    "embeddings= pickleLoad(\"EmbeddingScript1.pickle\")\n",
    "#Get the training data\n",
    "train_stories, train_orders, _ = pipeline(data_train, vocab)\n",
    "\n",
    "# get the length of the longest sentence\n",
    "max_sent_len = train_stories.shape[2]\n",
    "\n",
    "#Get validation data\n",
    "dev_stories, dev_orders, _ = pipeline(data_dev, vocab=vocab, max_sent_len_=max_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Script 2 ############ \n",
    "# Use the training data to define the vocab, and then try to adapt the Glove embeddings to this vocab\n",
    "\n",
    "# LOAD the Pickle file of pre-trained embeddings : Choose favorite\n",
    "#pre_learned_embeddings = pickleLoad(embeddings_file_to_load)\n",
    "\n",
    "\n",
    "#Get the training data and the vocabulary\n",
    "#train_stories, train_orders, vocab = pipeline(data_train)\n",
    "\n",
    "# get the length of the longest sentence\n",
    "#max_sent_len = train_stories.shape[2]\n",
    "\n",
    "#Get the word embeddings\n",
    "#embeddings = createWordEmbeddings(pre_learned_embeddings)\n",
    "\n",
    "#if(use_pca):\n",
    " #   embeddings = doPCA(embeddings,output_dimention_from_pca)\n",
    "\n",
    "#Get Validation data\n",
    "#dev_stories, dev_orders, _ = pipeline(data_dev, vocab=vocab, max_sent_len_= max_sent_len)\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displayDict(embeddings,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displayDict(vocab,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIONAL :\n",
    "# Use this in order to save the vocab and embeddings produced and only load them directly when needed\n",
    "#pickleSave(vocab, \"VocabScript2\")\n",
    "#pickleSave(embeddings, \"EmbeddingScript2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIONAL:\n",
    "# If the vocabs and embeddings were saved before can just call this cell\n",
    "\n",
    "#vocab_file = \"VocabScript1.pickle\"\n",
    "#embedding_file = \"EmbeddingScript1.pickle\"\n",
    "\n",
    "#vocab = pickleLoad(vocab_file)\n",
    "#embeddings = pickleLoad(embedding_file)\n",
    "\n",
    "# get the length of the longest sentence\n",
    "#max_sent_len = train_stories.shape[2]\n",
    "\n",
    "#Get Validation data\n",
    "#dev_stories, dev_orders, _ = pipeline(data_dev, vocab=vocab, max_sent_len_=max_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.show_data_instance(dev_stories, dev_orders, vocab, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD NEW TRAINING DATA\n",
    "def reorder_training_set(train_stories, train_orders):\n",
    "\n",
    "    new_stories = []\n",
    "    new_orders = []\n",
    "    for idx, story in enumerate(train_stories):\n",
    "        perm = np.random.permutation(5)            \n",
    "        new_story = story[perm, :]\n",
    "        new_order = train_orders[idx][perm]\n",
    "        new_stories.append(new_story)\n",
    "        new_orders.append(new_order)\n",
    "        \n",
    "    return np.array(new_stories), np.array(new_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############      DO PREPORCESSING END   #####################\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "The model we provide is a rudimentary, non-optimised model that essentially represents every word in a sentence with a fixed vector, sums these vectors up (per sentence) and puts a softmax at the end which aims to guess the order of sentences independently.\n",
    "\n",
    "First we define the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Imports\n",
    "from tensorflow.contrib import rnn\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:04:59.966529",
     "start_time": "2016-12-20T12:04:59.956638"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "### MODEL PARAMETERS ###\n",
    "target_size = 5\n",
    "vocab_size = len(vocab)\n",
    "input_size = len(embeddings[0])\n",
    "# n = len(train_stories)\n",
    "output_size = 5\n",
    "\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 32\n",
    "num_hidden_lstm = 64\n",
    "sentence_embedding_dim = 128\n",
    "attention_width = 32\n",
    "attention_instances = 1\n",
    "patience = 4\n",
    "\n",
    "learning_rate = 0.001\n",
    "clip_norm = 10.0\n",
    "\n",
    "regularizer = 0.001\n",
    "\n",
    "SE_methods = ['one_layer_LSTM', 'one_layer_biLSTM', 'two_layer_LSTM', 'two_layer_biLSTM', 'three_layer_LSTM', 'self_attention']\n",
    "SE_method = 'two_layer_biLSTM' # choose from SE_methods\n",
    "\n",
    "OPT_methods = ['original', 'hungarian', 'regression']\n",
    "OPT_method = 'hungarian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then we define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_permutation(x, batch_size):\n",
    "    # x will be a numpy array with the contents of the placeholder below\n",
    "    y = np.zeros_like(x, dtype=np.int32)\n",
    "    for b in range(batch_size):\n",
    "        for i in range(5):\n",
    "            y[b, x[b, i]] = 4 - i\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hungarian_method(x, batch_size):\n",
    "    l = list()\n",
    "    #print('x={}'.format(x[:3, :]))\n",
    "    #print('batch_size={}'.format(batch_size))\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        row_indices, column_indices = linear_sum_assignment(-x[b, :])\n",
    "        l.append(column_indices)\n",
    "        \n",
    "    l = np.array(l, dtype=np.int32)\n",
    "    #print('l={}'.format(l[:3]))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases, fwd_cell, sent_lens):\n",
    "\n",
    "    # Get lstm cell output - dynamic_rnn allows for different sequence lengths, sets output to 0 after and just maintains state\n",
    "    outputs, final_states = tf.nn.dynamic_rnn(fwd_cell, x, dtype=tf.float32, sequence_length=sent_lens)\n",
    "    \n",
    "    final_output = final_states[1] # final_states returns a tuple of (final_output, final_state)\n",
    "\n",
    "    return tf.matmul(final_output, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiRNN(x, weights, biases, fwd_cell, bwd_cell, sent_lens):\n",
    "   \n",
    "    outputs, final_states = tf.nn.bidirectional_dynamic_rnn(fwd_cell, bwd_cell, x, dtype=tf.float32, sequence_length=sent_lens)\n",
    "\n",
    "    states_concat = tf.concat([final_states[0], final_states[1]], 2) # concatenate the forward pass and backwards pass\n",
    "\n",
    "    final_output = states_concat[1] # states_concat returns a tuple of (final_context, final_state)\n",
    "\n",
    "    return tf.matmul(final_output, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwoLayerRNN(x, weights, biases, cell1, cell2, sent_lens):\n",
    "    \n",
    "    # Get outputs from 1 layer LSTM\n",
    "    outputs, final_states = tf.nn.dynamic_rnn(cell1, x, dtype=tf.float32, sequence_length=sent_lens, scope='layer1')\n",
    "    # Use outputs from previous layer as input to LSTM\n",
    "    outputs, final_states = tf.nn.dynamic_rnn(cell2, outputs, dtype=tf.float32, sequence_length=sent_lens, scope='layer2')\n",
    "    \n",
    "    final_output = final_states[1] # final_states returns a tuple of (final_output, final_state); get output only\n",
    "    \n",
    "    return tf.matmul(final_output, weights) + biases \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiLayerBiRNN(x, weights, biases, fwd_cell1, fwd_cell2, bwd_cell1, bwd_cell2, sent_lens):\n",
    "\n",
    "    # Get outputs from 1 layer LSTM\n",
    "    outputs, final_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "       fwd_cell1, bwd_cell1, x, dtype=tf.float32, sequence_length=sent_lens, scope='layer1')\n",
    "\n",
    "    # Concatenate outputs\n",
    "\n",
    "    output_concat = tf.concat([outputs[0], outputs[1]], 2)\n",
    "\n",
    "    # Use outputs from previous layer as input to LSTM\n",
    "    outputs, final_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "       fwd_cell2, bwd_cell2, output_concat, dtype=tf.float32, sequence_length=sent_lens, scope='layer2')\n",
    "\n",
    "    states_concat = tf.concat([final_states[0], final_states[1]], 2) # concatenate the forward pass and backwards pass\n",
    "\n",
    "    final_state = states_concat[1] # get final hidden state, ignore final context\n",
    "\n",
    "    return tf.matmul(final_state, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ThreeLayerRNN(x, weights, biases, cell1, cell2, cell3, sent_lens):\n",
    "    \n",
    "    # Get outputs from 1 layer LSTM\n",
    "    outputs, final_states = tf.nn.dynamic_rnn(cell1, x, dtype=tf.float32, sequence_length=sent_lens, scope='layer1')\n",
    "    # Use outputs from previous layer as input to LSTM\n",
    "    outputs, final_states = tf.nn.dynamic_rnn(cell2, outputs, dtype=tf.float32, sequence_length=sent_lens, scope='layer2')\n",
    "    outputs, final_states = tf.nn.dynamic_rnn(cell3, outputs, dtype=tf.float32, sequence_length=sent_lens, scope='layer3')\n",
    "    \n",
    "    final_output = final_states[1] # final_states returns a tuple of (final_output, final_state); get output only\n",
    "    \n",
    "    return tf.matmul(final_output, weights) + biases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelfAttention(x, weights, biases, fwd_cell1, fwd_cell2, bwd_cell1, bwd_cell2, sent_lens):\n",
    "    \"\"\"Implementation of self attention paper https://arxiv.org/pdf/1703.03130.pdf\"\"\"\n",
    "    \n",
    "        # Get outputs from 1 layer LSTM\n",
    "    outputs, final_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "       fwd_cell1, bwd_cell1, x, dtype=tf.float32, sequence_length=sent_lens, scope='layer1')\n",
    "\n",
    "    # Concatenate outputs\n",
    "\n",
    "    output_concat = tf.concat([outputs[0], outputs[1]], 2)\n",
    "\n",
    "    # Use outputs from previous layer as input to LSTM\n",
    "    outputs, final_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "       fwd_cell2, bwd_cell2, output_concat, dtype=tf.float32, sequence_length=sent_lens, scope='layer2')\n",
    "    \n",
    "    output_concat = tf.concat([outputs[0], outputs[1]], 2)\n",
    "    \n",
    "    #Compute Self Attention\n",
    "    \n",
    "    #outputs_concat is [batch_size x max_length x 2* num_hidden]\n",
    "    \n",
    "    #Tile weights for matmul\n",
    "    w1_tiled = tf.expand_dims(weights['attn_1'], axis=0)\n",
    "    w1_tiled = tf.tile(w1_tiled, [batch_size, 1,1])\n",
    "    w2_tiled = tf.expand_dims(weights['attn_2'], axis=0)\n",
    "    w2_tiled = tf.tile(w2_tiled, [batch_size, 1,1])\n",
    "    \n",
    "    a = tf.tanh(tf.matmul(output_concat, w1_tiled)) # [batch_size x max_length x attention_width]\n",
    "    \n",
    "    A = tf.nn.softmax(tf.matmul(a, w2_tiled), dim=1) # [batch_size x max_length x attention_instances]\n",
    "    \n",
    "    output_concat = tf.transpose(output_concat, [0,2,1]) # for easy matmul\n",
    "    \n",
    "    sentence_embedded = tf.matmul(output_concat, A) # [batch_size x 2*num_hidden x attention_instances]\n",
    "    \n",
    "    sentence_embedded = tf.contrib.layers.flatten(sentence_embedded) # flatten matrix of embeddings\n",
    "    \n",
    "    sentence_embedded =  tf.matmul(sentence_embedded, weights['lstm']) + biases['lstm']\n",
    "    \n",
    "    return sentence_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_embedding(sentence_embedding):\n",
    "\n",
    "    convolve_1d = tf.layers.conv1d(sentence_embedding, filters=128, kernel_size=3, padding='same', activation=tf.nn.relu)\n",
    "\n",
    "    return convolve_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_batch_relu_dropout(x, num_of_neurons, dropout_prob, phase, scope):\n",
    "    with tf.variable_scope(scope):\n",
    "        h1 = tf.contrib.layers.fully_connected(x, num_of_neurons, \n",
    "                                               activation_fn=None,\n",
    "                                               scope=scope)\n",
    "        h2 = tf.contrib.layers.batch_norm(h1, \n",
    "                                          center=True, scale=True, \n",
    "                                          is_training=phase,\n",
    "                                          scope='bn')\n",
    "        h3 = tf.layers.dropout(inputs=h2, rate=dropout_prob)\n",
    "        return tf.nn.relu(h3, 'relu')\n",
    "    \n",
    "def dense_relu_dropout(x, num_of_neurons, dropout_prob, scope):\n",
    "    with tf.variable_scope(scope):\n",
    "        h1 = tf.contrib.layers.fully_connected(x, num_of_neurons, \n",
    "                                               activation_fn=None,\n",
    "                                               scope=scope)\n",
    "        h2 = tf.layers.dropout(inputs=h1, rate=dropout_prob)\n",
    "        return tf.nn.relu(h2, 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:00.995336",
     "start_time": "2016-12-20T12:04:59.968153"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### MODEL ###\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## PLACEHOLDERS\n",
    "story = tf.placeholder(tf.int32, [None, None, None],\n",
    "                       \"story\")  # [batch_size x 5 x max_length]\n",
    "order = tf.placeholder(tf.int32, [None, None], \"order\")  # [batch_size x 5]\n",
    "dropout_prob = tf.placeholder(\n",
    "    tf.float32)  # to hold dropout probability (need placeholder as no dropout at prediction time)\n",
    "phase = tf.placeholder(tf.bool, name='phase')\n",
    "\n",
    "batch_size = tf.shape(story)[0]\n",
    "max_length = tf.shape(story)[2]\n",
    "\n",
    "sentences = [tf.reshape(x, [batch_size, -1]) for x in\n",
    "             tf.split(axis=1, num_or_size_splits=5,\n",
    "                      value=story)]  # 5 times [batch_size x max_length]\n",
    "\n",
    "# We need the lengths of each sentence as an input to the dynamic_rnn - find the number of nonzero elements\n",
    "# in each sentence\n",
    "sentence_lengths = [tf.count_nonzero(sentence, 1) for sentence in sentences]\n",
    "\n",
    "#### USE CUSTOM EMBEDDINGS #######\n",
    "# In order to restore to previous state reverse (comment uncommented and uncomment commented)\n",
    "\n",
    "# Word embeddings\n",
    "# initializer = tf.glorot_uniform_initializer()\n",
    "# embeddings = tf.get_variable(\"W\", [vocab_size, input_size], initializer=initializer)\n",
    "\n",
    "# sentences_embedded = [tf.nn.embedding_lookup(embeddings, sentence)   # 5 times[batch_size x max_seq_length x input_size]\n",
    "#                     for sentence in sentences]\n",
    "\n",
    "embeddings_array = np.zeros((vocab_size, input_size), dtype=np.float32)\n",
    "\n",
    "for k, val in embeddings.items():\n",
    "    embeddings_array[k] = val\n",
    "\n",
    "embeddings_var = tf.get_variable(\"W\", initializer=embeddings_array)\n",
    "\n",
    "embeddings_var = tf.cast(embeddings_var, tf.float32)\n",
    "sentences_embedded = [tf.nn.embedding_lookup(embeddings_var, sentence)\n",
    "                      # 5 times[batch_size x max_seq_length x input_size]\n",
    "                      for sentence in sentences]\n",
    "##################################\n",
    "\n",
    "#sentences_embedded = [convolution_embedding(sentences_embedded[i]) for i in range(5)]\n",
    "\n",
    "if SE_method == 'one_layer_LSTM':\n",
    "    fwd_cell = rnn.BasicLSTMCell(num_hidden_lstm)  # forward lstm cell\n",
    "    fwd_cell = rnn.DropoutWrapper(fwd_cell, output_keep_prob=1.0 - dropout_prob)\n",
    "\n",
    "    weights = {\n",
    "        'lstm': tf.get_variable('lstm',\n",
    "                                shape=[num_hidden_lstm, sentence_embedding_dim],\n",
    "                                initializer=tf.glorot_normal_initializer(),\n",
    "                                regularizer=tf.contrib.layers.l2_regularizer(\n",
    "                                    scale=regularizer))\n",
    "    }\n",
    "    biases = {\n",
    "        'lstm': tf.get_variable('bias_lstm',\n",
    "                                shape=[sentence_embedding_dim],\n",
    "                                initializer=tf.glorot_normal_initializer())\n",
    "    }\n",
    "\n",
    "    sentence_codes = [\n",
    "        RNN(sentences_embedded[i], weights['lstm'], biases['lstm'], fwd_cell,\n",
    "            sentence_lengths[i]) for i in range(5)]\n",
    "elif SE_method == 'one_layer_biLSTM':\n",
    "    fwd_cell = rnn.BasicLSTMCell(num_hidden_lstm)  # forward lstm cell\n",
    "    fwd_cell = rnn.DropoutWrapper(fwd_cell, output_keep_prob=1.0 - dropout_prob)\n",
    "    bwd_cell = rnn.BasicLSTMCell(\n",
    "        num_hidden_lstm)  # backwards lstm cell for bidirectional\n",
    "    bwd_cell = rnn.DropoutWrapper(bwd_cell, output_keep_prob=1.0 - dropout_prob)\n",
    "\n",
    "    weights = {\n",
    "        'bi': tf.get_variable('bi', shape=[2 * num_hidden_lstm,\n",
    "                                           sentence_embedding_dim],\n",
    "                              initializer=tf.glorot_normal_initializer(),\n",
    "                              regularizer=tf.contrib.layers.l2_regularizer(\n",
    "                                     scale=regularizer))\n",
    "        # 2 times num_hidden_lstm because we concat the outputs of the 2 directions\n",
    "    }\n",
    "    biases = {\n",
    "        'bi': tf.get_variable('bias_bi',\n",
    "                                shape=[sentence_embedding_dim],\n",
    "                                initializer=tf.glorot_normal_initializer())\n",
    "    }\n",
    "\n",
    "    sentence_codes = [\n",
    "        BiRNN(sentences_embedded[i], weights['bi'], biases['bi'], fwd_cell,\n",
    "              bwd_cell, sentence_lengths[i]) for i in range(5)]\n",
    "elif SE_method == 'two_layer_LSTM':\n",
    "    fwd_cell = rnn.BasicLSTMCell(num_hidden_lstm)  # forward lstm cell\n",
    "    fwd_cell = rnn.DropoutWrapper(fwd_cell, output_keep_prob=1.0 - dropout_prob)\n",
    "    fwd_cell2 = rnn.BasicLSTMCell(num_hidden_lstm)\n",
    "    fwd_cell2 = rnn.DropoutWrapper(fwd_cell2,\n",
    "                                   output_keep_prob=1.0 - dropout_prob)\n",
    "\n",
    "    weights = {\n",
    "        'layer': tf.get_variable('layer',\n",
    "                                 shape=[num_hidden_lstm,\n",
    "                                        sentence_embedding_dim],\n",
    "                                 initializer=tf.glorot_normal_initializer(),\n",
    "                                 regularizer=tf.contrib.layers.l2_regularizer(\n",
    "                                     scale=regularizer))\n",
    "    }\n",
    "    biases = {\n",
    "        'layer': tf.get_variable('bias_layer',\n",
    "                                shape=[sentence_embedding_dim],\n",
    "                                initializer=tf.glorot_normal_initializer())\n",
    "    }\n",
    "\n",
    "    sentence_codes = [\n",
    "        TwoLayerRNN(sentences_embedded[i], weights['layer'], biases['layer'],\n",
    "                    fwd_cell, fwd_cell2, sentence_lengths[i]) for i in range(5)]\n",
    "elif SE_method == 'three_layer_LSTM':\n",
    "    fwd_cell = rnn.BasicLSTMCell(num_hidden_lstm)  # forward lstm cell\n",
    "    fwd_cell = rnn.DropoutWrapper(fwd_cell, output_keep_prob=1.0 - dropout_prob)\n",
    "    fwd_cell2 = rnn.BasicLSTMCell(num_hidden_lstm)\n",
    "    fwd_cell2 = rnn.DropoutWrapper(fwd_cell2,\n",
    "                                   output_keep_prob=1.0 - dropout_prob)\n",
    "    fwd_cell3 = rnn.BasicLSTMCell(num_hidden_lstm)\n",
    "    fwd_cell3 = rnn.DropoutWrapper(fwd_cell3,\n",
    "                                   output_keep_prob=1.0 - dropout_prob)\n",
    "\n",
    "    weights = {\n",
    "        'layer': tf.get_variable('layer',\n",
    "                                 shape=[num_hidden_lstm,\n",
    "                                        sentence_embedding_dim],\n",
    "                                 initializer=tf.glorot_normal_initializer(),\n",
    "                                 regularizer=tf.contrib.layers.l2_regularizer(\n",
    "                                     scale=regularizer))\n",
    "    }\n",
    "    biases = {\n",
    "        'layer': tf.get_variable('bias_layer',\n",
    "                                 shape=[sentence_embedding_dim],\n",
    "                                 initializer=tf.glorot_normal_initializer())\n",
    "    }\n",
    "\n",
    "    sentence_codes = [\n",
    "        ThreeLayerRNN(sentences_embedded[i], weights['layer'], biases['layer'],\n",
    "                      fwd_cell, fwd_cell2, fwd_cell3, sentence_lengths[i]) for i\n",
    "        in range(5)]\n",
    "    \n",
    "elif SE_method == 'two_layer_biLSTM':\n",
    "    fwd_cell1 = rnn.BasicLSTMCell(num_hidden_lstm)  # forward lstm cell\n",
    "    fwd_cell1 = rnn.DropoutWrapper(fwd_cell1, output_keep_prob=1.0 - dropout_prob)\n",
    "    bwd_cell1 = rnn.BasicLSTMCell(num_hidden_lstm)  # backwards lstm cell for bidirectional\n",
    "    bwd_cell1= rnn.DropoutWrapper(bwd_cell1, output_keep_prob=1.0 - dropout_prob)\n",
    "\n",
    "    fwd_cell2 = rnn.BasicLSTMCell(2*num_hidden_lstm)  # forward lstm cell\n",
    "    fwd_cell2 = rnn.DropoutWrapper(fwd_cell2, output_keep_prob=1.0 - dropout_prob)\n",
    "    bwd_cell2 = rnn.BasicLSTMCell(2*num_hidden_lstm)  # backwards lstm cell for bidirectional\n",
    "    bwd_cell2= rnn.DropoutWrapper(bwd_cell2, output_keep_prob=1.0 - dropout_prob)\n",
    "\n",
    "    weights = {\n",
    "       'bi': tf.get_variable('bi', shape=[4 * num_hidden_lstm,\n",
    "                                          sentence_embedding_dim],\n",
    "                             initializer=tf.glorot_normal_initializer(),\n",
    "                             regularizer=tf.contrib.layers.l2_regularizer(\n",
    "                                    scale=regularizer))\n",
    "    }\n",
    "    biases = {\n",
    "       'bi': tf.get_variable('bias_bi',\n",
    "                               shape=[sentence_embedding_dim],\n",
    "                               initializer=tf.glorot_normal_initializer())\n",
    "    }\n",
    "\n",
    "    sentence_codes = [\n",
    "       MultiLayerBiRNN(sentences_embedded[i], weights['bi'], biases['bi'], fwd_cell1, fwd_cell2,\n",
    "             bwd_cell1, bwd_cell2, sentence_lengths[i]) for i in range(5)]\n",
    "    \n",
    "elif SE_method == 'self_attention':\n",
    "    fwd_cell1 = rnn.BasicLSTMCell(num_hidden_lstm)  # forward lstm cell\n",
    "    fwd_cell1 = rnn.DropoutWrapper(fwd_cell1, output_keep_prob=1.0 - dropout_prob)\n",
    "    bwd_cell1 = rnn.BasicLSTMCell(num_hidden_lstm)  # backwards lstm cell for bidirectional\n",
    "    bwd_cell1= rnn.DropoutWrapper(bwd_cell1, output_keep_prob=1.0 - dropout_prob)\n",
    "\n",
    "    fwd_cell2 = rnn.BasicLSTMCell(num_hidden_lstm)  # forward lstm cell\n",
    "    fwd_cell2 = rnn.DropoutWrapper(fwd_cell2, output_keep_prob=1.0 - dropout_prob)\n",
    "    bwd_cell2 = rnn.BasicLSTMCell(num_hidden_lstm)  # backwards lstm cell for bidirectional\n",
    "    bwd_cell2= rnn.DropoutWrapper(bwd_cell2, output_keep_prob=1.0 - dropout_prob)\n",
    "\n",
    "    weights = {\n",
    "        'lstm' : tf.get_variable('lstm',\n",
    "                                shape=[2*num_hidden_lstm, sentence_embedding_dim],\n",
    "                                initializer=tf.glorot_normal_initializer(),\n",
    "                                regularizer=tf.contrib.layers.l2_regularizer(\n",
    "                                    scale=regularizer)),\n",
    "        'attn_1' : tf.get_variable('attn_1',\n",
    "                                shape=[2*num_hidden_lstm, attention_width],\n",
    "                                initializer=tf.glorot_normal_initializer(),\n",
    "                                regularizer=tf.contrib.layers.l2_regularizer(\n",
    "                                    scale=regularizer)),\n",
    "        'attn_2' : tf.get_variable('attn_2',\n",
    "                                shape=[attention_width, attention_instances],\n",
    "                                initializer=tf.glorot_normal_initializer(),\n",
    "                                regularizer=tf.contrib.layers.l2_regularizer(\n",
    "                                    scale=regularizer))\n",
    "    }\n",
    "    biases = {\n",
    "        'lstm': tf.get_variable('bias_lstm',\n",
    "                                shape=[sentence_embedding_dim],\n",
    "                                initializer=tf.glorot_normal_initializer())\n",
    "    }\n",
    "\n",
    "    sentence_codes = [\n",
    "        SelfAttention(sentences_embedded[i], weights, biases, fwd_cell1,\n",
    "                      fwd_cell2, bwd_cell1, bwd_cell2, sentence_lengths[i]) for i in range(5)]\n",
    "else:\n",
    "    raise InvalidArgumentException('Choose a valid sentence embedding method!')\n",
    "\n",
    "h_temp = tf.concat(axis=1,\n",
    "                   values=sentence_codes)  # [batch_size x 5*sentence_embedding_dim]\n",
    "h = tf.reshape(h_temp, [batch_size, 5 * sentence_embedding_dim])\n",
    "\n",
    "# dense1 = dense_batch_relu_dropout(x=h, num_of_neurons=n_hidden_1, dropout_prob=dropout_prob, phase=phase, scope='layer1')\n",
    "# dense2 = dense_batch_relu_dropout(x=dense1, num_of_neurons=n_hidden_2, dropout_prob=dropout_prob, phase=phase, scope='layer2')\n",
    "dense1 = dense_relu_dropout(x=h, num_of_neurons=n_hidden_1,\n",
    "                            dropout_prob=dropout_prob, scope='layer1')\n",
    "dense2 = dense_relu_dropout(x=dense1, num_of_neurons=n_hidden_2,\n",
    "                            dropout_prob=dropout_prob, scope='layer2')\n",
    "\n",
    "if OPT_method == 'original':\n",
    "    # ORIGINAL SETUP\n",
    "    logits_flat = tf.contrib.layers.fully_connected(inputs=dense2,\n",
    "                                                num_outputs=5 * target_size,\n",
    "                                                activation_fn=None)  # [batch_size x 5*sentence_embedding_dim]\n",
    "    logits = tf.reshape(logits_flat, [-1, 5, target_size])  # [batch_size x 5 x target_size]\n",
    "    \n",
    "    temp = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=order)\n",
    "    loss = tf.reduce_sum(temp)\n",
    "\n",
    "    unpacked_logits = [tensor for tensor in tf.unstack(logits, axis=1)]\n",
    "    softmaxes = [tf.nn.softmax(tensor) for tensor in unpacked_logits]\n",
    "    softmaxed_logits = tf.stack(softmaxes, axis=1)\n",
    "\n",
    "    predict = tf.argmax(softmaxed_logits, 2)\n",
    "\n",
    "elif OPT_method == 'hungarian':\n",
    "    # ORIGINAL + MAXIMUM WEIGHTED ASSIGNMENT\n",
    "    logits_flat = tf.contrib.layers.fully_connected(inputs=dense2,\n",
    "                                                num_outputs=5 * target_size,\n",
    "                                                activation_fn=None)  # [batch_size x 5*sentence_embedding_dim]\n",
    "    logits = tf.reshape(logits_flat, [-1, 5, target_size])  # [batch_size x 5 x target_size]\n",
    "    temp = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                          labels=order)\n",
    "    loss = tf.reduce_sum(temp) + tf.add_n(tf.losses.get_regularization_losses())\n",
    "\n",
    "    unpacked_logits = [tensor for tensor in tf.unstack(logits, axis=1)]\n",
    "    softmaxes = [tf.nn.softmax(tensor) for tensor in unpacked_logits]\n",
    "    softmaxed_logits = tf.stack(softmaxes, axis=1)\n",
    "\n",
    "    predict = tf.py_func(hungarian_method, [softmaxed_logits, batch_size], tf.int32)\n",
    "\n",
    "elif OPT_method == 'regression':\n",
    "    # REGRESSION + MSE\n",
    "    logits_flat = tf.contrib.layers.fully_connected(inputs=dense2, num_outputs=target_size, activation_fn=None)  # [batch_size x 5*sentence_embedding_dim]\n",
    "    loss = tf.losses.mean_squared_error(predictions=logits_flat, labels=order) + tf.add_n(tf.losses.get_regularization_losses())\n",
    "\n",
    "    values, indices = tf.nn.top_k(logits_flat, 5)\n",
    "    predict = tf.py_func(inverse_permutation, [indices, batch_size], tf.int32)\n",
    "else:\n",
    "    raise InvalidArgumentException('Choose a valid optimizing function!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We built our model, together with the loss and the prediction function, all we are left with now is to build an optimiser on the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:01.184409",
     "start_time": "2016-12-20T12:05:00.997016"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# minimize in two steps, to do gradient clipping before applying it\n",
    "opt_op = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "gradients, variables = zip(*opt_op.compute_gradients(loss))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, clip_norm)\n",
    "optimize = opt_op.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "#optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training \n",
    "\n",
    "We defined the preprocessing pipeline, set the model up, so we can finally train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:54.615600",
     "start_time": "2016-12-20T12:05:01.186008"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BATCH_SIZE = 128\\n#train_stories = train_stories[:1000]\\n#train_orders = train_orders[:1000]\\nverbose = True\\nuse_early_stopping = True\\n\\nwith tf.Session() as sess:\\n    if(use_early_stopping):\\n        early_stopper = EarlyStopper(patience,True)\\n    \\n    sess.run(tf.initialize_all_variables())\\n    n = train_stories.shape[0]\\n    \\n    for epoch in range(100):\\n        print(\\'----- Epoch\\', epoch, \\'-----\\')\\n        start = time.time()\\n        \\n        total_loss = 0\\n        train_stories, train_orders = reorder_training_set(train_stories, train_orders)\\n        \\n        perm = np.random.permutation(n)\\n        for i in range(n // BATCH_SIZE):\\n            indices = perm[i * BATCH_SIZE: (i + 1) * BATCH_SIZE]\\n            inst_story = train_stories[indices]\\n            inst_order = train_orders[indices]\\n            feed_dict = {story: inst_story, order: inst_order, dropout_prob: 0.5, phase: True}\\n            #o, temp, prediction, _, current_loss= sess.run([order, logits_flat, predict, optimize, loss], feed_dict=feed_dict)\\n            _, current_loss= sess.run([optimize, loss], feed_dict=feed_dict)\\n            \\n            \\n            if(i % 25 == 0 and verbose):\\n                print(\"Current Epoch %: {}/{} loss:{}\".format(i, n // BATCH_SIZE, current_loss))\\n                \\n            total_loss += current_loss\\n\\n        print(\\' Train loss:\\', total_loss / n)\\n\\n        train_feed_dict = {story: train_stories, order: train_orders, dropout_prob: 0.0, phase: False}\\n        train_predicted = sess.run(predict, feed_dict=train_feed_dict)\\n        train_accuracy = nn.calculate_accuracy(train_orders, train_predicted)\\n        print(\\' Train accuracy:\\', train_accuracy)\\n        \\n        dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\\n        dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\\n        dev_accuracy = nn.calculate_accuracy(dev_orders, dev_predicted)\\n        print(\\' Dev accuracy:\\', dev_accuracy)\\n        \\n        finish = time.time()\\n        print(\\'Took {} seconds\\'.format(finish - start))\\n        \\n        if(use_early_stopping):\\n            if(early_stopper.checkEarlyStopping(dev_accuracy,sess)):\\n                break\\n\\n    if(use_early_stopping):\\n        # LOAD EARLY STOPPED MODEL\\n        print(\"Training Stopped, Loading saved model with max. dev accuracy from early stopping\")\\n        saver = tf.train.Saver()\\n        saver.restore(sess, \\'./model/model.checkpoint\\')\\n\\n        # MAKE SURE IT GIVES THE SAME PREDICTIONS AS BEFORE\\n        print(\"Calculating Dev Accuracy for the early stopped model: \")\\n        dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\\n        dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\\n        dev_accuracy = nn.calculate_accuracy(dev_orders, dev_predicted)\\n        print(\"Dev Accuracy : {}\".format(dev_accuracy))\\n    else:\\n        nn.save_model(sess)\\n        \\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''BATCH_SIZE = 128\n",
    "#train_stories = train_stories[:1000]\n",
    "#train_orders = train_orders[:1000]\n",
    "verbose = True\n",
    "use_early_stopping = True\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if(use_early_stopping):\n",
    "        early_stopper = EarlyStopper(patience,True)\n",
    "    \n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    n = train_stories.shape[0]\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        print('----- Epoch', epoch, '-----')\n",
    "        start = time.time()\n",
    "        \n",
    "        total_loss = 0\n",
    "        train_stories, train_orders = reorder_training_set(train_stories, train_orders)\n",
    "        \n",
    "        perm = np.random.permutation(n)\n",
    "        for i in range(n // BATCH_SIZE):\n",
    "            indices = perm[i * BATCH_SIZE: (i + 1) * BATCH_SIZE]\n",
    "            inst_story = train_stories[indices]\n",
    "            inst_order = train_orders[indices]\n",
    "            feed_dict = {story: inst_story, order: inst_order, dropout_prob: 0.5, phase: True}\n",
    "            #o, temp, prediction, _, current_loss= sess.run([order, logits_flat, predict, optimize, loss], feed_dict=feed_dict)\n",
    "            _, current_loss= sess.run([optimize, loss], feed_dict=feed_dict)\n",
    "            \n",
    "            \n",
    "            if(i % 25 == 0 and verbose):\n",
    "                print(\"Current Epoch %: {}/{} loss:{}\".format(i, n // BATCH_SIZE, current_loss))\n",
    "                \n",
    "            total_loss += current_loss\n",
    "\n",
    "        print(' Train loss:', total_loss / n)\n",
    "\n",
    "        train_feed_dict = {story: train_stories, order: train_orders, dropout_prob: 0.0, phase: False}\n",
    "        train_predicted = sess.run(predict, feed_dict=train_feed_dict)\n",
    "        train_accuracy = nn.calculate_accuracy(train_orders, train_predicted)\n",
    "        print(' Train accuracy:', train_accuracy)\n",
    "        \n",
    "        dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\n",
    "        dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\n",
    "        dev_accuracy = nn.calculate_accuracy(dev_orders, dev_predicted)\n",
    "        print(' Dev accuracy:', dev_accuracy)\n",
    "        \n",
    "        finish = time.time()\n",
    "        print('Took {} seconds'.format(finish - start))\n",
    "        \n",
    "        if(use_early_stopping):\n",
    "            if(early_stopper.checkEarlyStopping(dev_accuracy,sess)):\n",
    "                break\n",
    "\n",
    "    if(use_early_stopping):\n",
    "        # LOAD EARLY STOPPED MODEL\n",
    "        print(\"Training Stopped, Loading saved model with max. dev accuracy from early stopping\")\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, './model/model.checkpoint')\n",
    "\n",
    "        # MAKE SURE IT GIVES THE SAME PREDICTIONS AS BEFORE\n",
    "        print(\"Calculating Dev Accuracy for the early stopped model: \")\n",
    "        dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\n",
    "        dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\n",
    "        dev_accuracy = nn.calculate_accuracy(dev_orders, dev_predicted)\n",
    "        print(\"Dev Accuracy : {}\".format(dev_accuracy))\n",
    "    else:\n",
    "        nn.save_model(sess)\n",
    "        \n",
    "'''\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "################     ERROR ANALYSIS      #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### CONFUSION MATRIX  ####\\nprint(\"The Confusion matrix (true order vs predicted order) is as follows:\")\\nwith tf.Session() as sess:\\n    # LOAD EARLY STOPPED MODEL\\n    saver = tf.train.Saver()\\n    saver.restore(sess, \\'./model/model.checkpoint\\')\\n\\n    # MAKE SURE IT GIVES THE SAME PREDICTIONS AS BEFORE\\n    dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\\n    dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\\n   \\n    \\n    # CREATE THE CONFUSION MATRIX\\n    cm_dev = create_confusion_matrix(dev_predicted, dev_orders)\\n    util.plot_confusion_matrix_dict(cm_dev,90, outside_label=\"None\")\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''### CONFUSION MATRIX  ####\n",
    "print(\"The Confusion matrix (true order vs predicted order) is as follows:\")\n",
    "with tf.Session() as sess:\n",
    "    # LOAD EARLY STOPPED MODEL\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.checkpoint')\n",
    "\n",
    "    # MAKE SURE IT GIVES THE SAME PREDICTIONS AS BEFORE\n",
    "    dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\n",
    "    dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\n",
    "   \n",
    "    \n",
    "    # CREATE THE CONFUSION MATRIX\n",
    "    cm_dev = create_confusion_matrix(dev_predicted, dev_orders)\n",
    "    util.plot_confusion_matrix_dict(cm_dev,90, outside_label=\"None\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n### ERROR EXAMPLES  ####\\nNumber_of_missclassified_exaples_to_display = 5\\n\\nwith tf.Session() as sess:\\n    # LOAD EARLY STOPPED MODEL\\n    saver = tf.train.Saver()\\n    saver.restore(sess, './model/model.checkpoint')\\n\\n    # MAKE SURE IT GIVES THE SAME PREDICTIONS AS BEFORE\\n    dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\\n    dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\\n    \\n    #GET THE ERROR EXAMPLES\\n    errors  = getErrors(data_dev,dev_orders,dev_predicted)\\n    displayErrors(errors, Number_of_missclassified_exaples_to_display)\\n\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "### ERROR EXAMPLES  ####\n",
    "Number_of_missclassified_exaples_to_display = 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # LOAD EARLY STOPPED MODEL\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.checkpoint')\n",
    "\n",
    "    # MAKE SURE IT GIVES THE SAME PREDICTIONS AS BEFORE\n",
    "    dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\n",
    "    dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\n",
    "    \n",
    "    #GET THE ERROR EXAMPLES\n",
    "    errors  = getErrors(data_dev,dev_orders,dev_predicted)\n",
    "    displayErrors(errors, Number_of_missclassified_exaples_to_display)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Get the number of OOV and PAD tokens in each missclassified phrase and display them as histograms\\nstats = getPADandOOVHistogramsOnErrors(errors,dev_stories)\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Get the number of OOV and PAD tokens in each missclassified phrase and display them as histograms\n",
    "stats = getPADandOOVHistogramsOnErrors(errors,dev_stories)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"The histogram of the number of padding tokens in missclassified phrases:\")\\nplot_histogram(stats,\\'PAD_hist\\')\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"The histogram of the number of padding tokens in missclassified phrases:\")\n",
    "plot_histogram(stats,'PAD_hist')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"The histogram of the number of OOV tokens in missclassified phrases:\")\\nplot_histogram(stats,\\'OOV_hist\\')\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"The histogram of the number of OOV tokens in missclassified phrases:\")\n",
    "plot_histogram(stats,'OOV_hist')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## Get the histogram of number of OOV and PAD tokens in each phrase for the full dev set\\nfull_devset_stats = getFullPadandOOVHistorgrams(dev_stories)\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## Get the histogram of number of OOV and PAD tokens in each phrase for the full dev set\n",
    "full_devset_stats = getFullPadandOOVHistorgrams(dev_stories)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"The histogram of the number of padding tokens in all phrases:\")\\nplot_histogram(full_devset_stats,\\'PAD_hist\\')\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"The histogram of the number of padding tokens in all phrases:\")\n",
    "plot_histogram(full_devset_stats,'PAD_hist')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"The histogram of the number of OOV tokens in all phrases:\")\\nplot_histogram(full_devset_stats,\\'OOV_hist\\')\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"The histogram of the number of OOV tokens in all phrases:\")\n",
    "plot_histogram(full_devset_stats,'OOV_hist')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Get the frequency of the words in the missclassified phrases and plot it\\nword_freq = getErrorWordFrequency(errors,dev_stories,vocab)\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Get the frequency of the words in the missclassified phrases and plot it\n",
    "word_freq = getErrorWordFrequency(errors,dev_stories,vocab)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Frequency of words in the missclassified phrases\")\\nplot_word_histogram(word_freq,10,[\\'<PAD>\\',\\'.\\'])\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"Frequency of words in the missclassified phrases\")\n",
    "plot_word_histogram(word_freq,10,['<PAD>','.'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Get the full frequency of words in the dev set and plot it \\nnorma_freq=getWordFrequency(dev_stories,vocab)\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Get the full frequency of words in the dev set and plot it \n",
    "norma_freq=getWordFrequency(dev_stories,vocab)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"frequency of words in all phrases\")\\nplot_word_histogram(norma_freq,10,[\\'<PAD>\\',\\'.\\'])\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"frequency of words in all phrases\")\n",
    "plot_word_histogram(norma_freq,10,['<PAD>','.'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Get the ratio of the number of times a word occurs in missclassified exampled\\n#vs the total number of times the word appears and plot it\\nfreq_hist = freq_ratios(norma_freq,word_freq)\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Get the ratio of the number of times a word occurs in missclassified exampled\n",
    "#vs the total number of times the word appears and plot it\n",
    "freq_hist = freq_ratios(norma_freq,word_freq)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Ratio of word frequencies missclassified/total\")\\nplot_word_histogram(freq_hist,10,[\\'<PAD>\\',\\'.\\'])\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"Ratio of word frequencies missclassified/total\")\n",
    "plot_word_histogram(freq_hist,10,['<PAD>','.'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############       ERROR ANALYSIS END    ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Assess Accuracy (40 pts) \n",
    "\n",
    "We assess how well your model performs on an unseen test set. We will look at the accuracy of the predicted sentence order, on sentence level, and will score them as followis:\n",
    "\n",
    "* 0 - 10 pts: 45% <= accuracy < 50%, linear\n",
    "* 10 - 20 pts: 50% <= accuracy < 55, linear\n",
    "* 20 - 40 pts: 55 <= accuracy < 60, linear\n",
    "* extra 0-10 pts: 60 <= accuracy < 70, linear\n",
    "\n",
    "The **linear** mapping maps any accuracy value between the lower and upper bound linearly to a score. For example, if your model's accuracy score is $acc=54.5\\%$, then your score is $10 + 10\\frac{acc-50}{55-50}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Change the following lines so that they construct the test set in the same way you constructed the dev set in the code above. We will insert the test set instead of the dev set here. **`test_feed_dict` variable must stay named the same**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:54.755730",
     "start_time": "2016-12-20T12:05:54.617471"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# LOAD THE DATA\n",
    "data_test = nn.load_corpus(data_path + \"dev.tsv\")\n",
    "# make sure you process this with the same pipeline as you processed your dev set\n",
    "test_stories, test_orders, _ = pipeline(data_test, vocab=vocab, max_sent_len_=max_sent_len)\n",
    "\n",
    "# THIS VARIABLE MUST BE NAMED `test_feed_dict`\n",
    "test_feed_dict = {story: test_stories, order: test_orders, dropout_prob: 0.0, phase: False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads your model, computes accuracy, and exports the result. **DO NOT** change this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-20T12:05:55.116609",
     "start_time": "2016-12-20T12:05:54.758571"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49994655264564403"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! ASSESSMENT 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "with tf.Session() as sess:\n",
    "    # LOAD THE MODEL\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.checkpoint')\n",
    "    \n",
    "    # RUN TEST SET EVALUATION\n",
    "    dev_predicted = sess.run(predict, feed_dict=test_feed_dict)\n",
    "    dev_accuracy = nn.calculate_accuracy(dev_orders, dev_predicted)\n",
    "\n",
    "dev_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 1 is marked with ** __ points**. \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Describe your Approach\n",
    "\n",
    "Enter a 1000 words max description of your approach **in this cell**.\n",
    "Make sure to provide:\n",
    "- an **error analysis** of the types of errors your system makes\n",
    "- compare your system with the model we provide, focus on differences and draw useful comparations between them\n",
    "\n",
    "Should you need to include figures in your report, make sure they are Python-generated (matplotlib, seaborn, bokeh are all included in the stat-nlp-book Docker image). For that, feel free to create new cells after this cell (before Assessment 2 cell). Link online images at your risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In this task of finding the sentence order in a paragraph, our approach was broken down into the following tasks:\n",
    "\n",
    "+ Tokenising, making a vocabulary  and creating word embeddings.\n",
    "+ Creating Sentence embeddings using the word embeddings.\n",
    "+ Making sentence order predictions based on the sentence embeddings.\n",
    "\n",
    "In the following sections, we break down how we tackled each of these components in detail.\n",
    "\n",
    "### Word embeddings and Tokenisation\n",
    "The initial model provided had a fairly simple approach to data preprocessing and tokenisation. The steps followed where (1) Tokenise the sentences into words by splitting them on white-spaces, (2) making a vocabulary (that maps tokens to unique integers) out of the tokens found in the training set, (3) add OOV and PAD tokens to account for unseen words and make all the sentences the same length and (4) assign to all tokens a random vector embedding. \n",
    "\n",
    "Our approach was fairly different and was centered on the pre-trained Glove embeddings from Stanford University. In fact our approach consisted of (1) Get the N most popular (in terms of frequency in the English language) words according to Glove and define our vocab and word embeddings. (2) Set the PAD tokens to 0 and the OOV tokens to the average of the unused embeddings on the Glove set and (3) tokenise the sentences and map the tokens to the embeddings obtained in the previous step.  \n",
    "\n",
    "In order for our procedure to work, we required a tokenisation procedure that would at best match the Glove tokens, so that we minimize the amount of OOVs present our training and test sets. The initial tokenising function was too simplistic, and some of the important steps we took to achieve this where the following:\n",
    "\n",
    " - separate punctuation from words\n",
    " - separate grammatical endings (e.g. \"'s\", \"n't\") from the base word\n",
    " - separate currency symbols and numbers\n",
    " - lowercase all words\n",
    "\n",
    "One thing we noticed when using Glove was that it provided 50, 100, 200 and 300 dimensional embeddings. In order to provide us with more flexibility, and in an attempt to perhaps keep more of the information richness of higher dimensional embeddings while avoiding overfitting, we have implemented the option of using PCA on our embeddings. This allowed us to experiment with any arbitrary dimensionality in training our models while attempting to as much of the information present in the higher dimensional embeddings as possible.\n",
    "\n",
    "Finally, it is interesting to note that in our approach we also attempted to use the training set to create a vocabulary (for consistency the initial approach given) and then create word embeddings using this vocabulary and Glove, but we noticed a smaller performance of our models.\n",
    "\n",
    "### Sentence embeddings\n",
    "In terms of sentence embeddings, the initial model summed all the word embeddings in the sentence to obtain its sentence embeddings. This simple approach does not rely on the training set. Although this approach eliminates the risk of overfitting, it has both an extremely high bias and a lack of any conceptual backing, which makes it less than ideal.\n",
    "\n",
    "In contrast to this, we chose to use representation learning with Recurrent Neural networks in order to learn the sentence embeddings from our data. More precisely, we have tried the follwing basic architectures, all of which which take as an input the word-embedded sentences and output the sentence embeddings:\n",
    "+ A Simple LSTM.\n",
    "+ A Bi-directional LSTM.\n",
    "+ A two layer LSTM.\n",
    "+ A two layer Bi-directional LSTM.\n",
    "\n",
    "On top of these architectures, we have also implemented the following variations in an attempt to maximise our performance:\n",
    "+ Attention\n",
    "+ CNNs-layers included\n",
    "\n",
    "Finally, in order to combat overfitting, we have experimented with the following techniques:\n",
    "+ Dropout \n",
    "+ Early Stopping\n",
    "+ Data Aumentation (shuffling the sentences in the training set)\n",
    "+ Regulatisation (l2)\n",
    "\n",
    "### Sentence Ordering\n",
    "Once the sentences are embedded we need a way to predict a sentence order. It is possible to do this in two ways: Regression and Classification. In Classification, the model will output a (5,5) matrix where the rows are the sentences and the columns are the probability of being in a position. In Regression the model will output the positions of the sentences directly.\n",
    "\n",
    "While the initial solution just treated Classification through a linear regressor, we are usign non-linear Multi-layer perceptrons (MLP) and attempting both regression and classification. Details of our approach for these two techniques are described below:\n",
    "\n",
    "##### Sentence ordering via Classification\n",
    "For classificaiton we implemented an MLP with 2 hidden layers with Relu activations and a 25-neuron softmax output layer. To train the model, we used cross-entropy loss and the RMS-prop optimiser.\n",
    "\n",
    "The last challenge we had to face is how to obtain the final ordering from our (5,5) output. The initial model used a greedy approach but this resulted in the same position being assigned  a sentence more than once. We wanted to avoid this while maximising the probability of the whole paragraph. We identified this as an instance of the Assignment problem, and hence used the Hungarian method in order to solve it. !!!!!!!!! SHOULD WE REFERENCE THE HUNGARIAN MERTOD??????!!!!!!!!!\n",
    "\n",
    "##### Sentence ordering via Regression\n",
    "For regression, we again used an MLP with 2 hidden layers, but we now have a 5-neuron linear output layer instead. In order to train it, we used the Mean Squarred Error (MSE) loss and the Adam optimizer.\n",
    "\n",
    "### Model Selection and Tunning\n",
    "In order to select our final model we had to compromise between  getting a model that achieves good generalisation performance and catering to the limited computational resources we had our disposal. We decided to use the dev set for validation for our models, and proceed in three times : (1) Select the dimentionality of the word embeddings (2) Select whether to use Classification or Regression, (3) Select a base architecture form the list above and (4) Tune this base architecture to get the highest possible score.\n",
    "\n",
    "After establishing that using 200D data was the best setup that kept us from running into memory issues, we experimented  with the regression and classification styles. It became clear that  using the classification method gave better performance, hence we proceeded with this technique. Then, keeping all hyperparameters equal, we trained all the base architectures listed, which gave the results listed below:\n",
    "\n",
    "| Model         | Accuracy on the validation set |\n",
    "| ------------- |:------------------:|\n",
    "| LSTM |   57.3276    | \n",
    "| Bi-directional LSTM    |57.7552      |  \n",
    "| Two layer LSTM   |  57.6269         | \n",
    "| Two layer Bi-directional LSTM | 57.9583          |   \n",
    "\n",
    "As we can see, the model that gave the best performance was the the two-layer bi-directional LSTM, so we chose it to proceed.\n",
    "\n",
    "We finnaly tuned this architecture by experimenting with (1) the number of hidden layer neurons, (2) the LSTM hindden neurons, (3) adding attention, (4) adding a CNN !!!!BAD WORDING!!!!. \n",
    "\n",
    "Our final model has the following specs:   !!!!!!!! ADD THE SPEEEECCCSSS !!!!!!!!!!!!!!!!  . It achieve an overall accuracy on the dev set of !!!!!!! AADD THE FINAL ACCURACY !!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "### Error Analysis \n",
    "We finally used our selected model and performed error analysis on it. Our purpose was to figure out if there are any particular types of errors that it still makes in an attempt to find out how we could address them.\n",
    "\n",
    "Our approach started with creating the Confusion Matrix (CM) of our model on the dev set, which is shown as the output of the Fig. 1 cell below. This CM shows the correct classification for each sentence in the dev set vs the classification that was predicted by our model, the color coding showing how many sentences fall into each configuration. Diagonal values then represent correctly classified sentences. As we can see from Fig. 1, our model does a good job at classifying sentences that should go in positions 0 and 4, but drops for the middle positions.\n",
    " \n",
    "In order to attempt to gain further insight on the mechanisms at play, we proceed by answering a series of questions using the dev set:\n",
    "##### Are OOVs or PADs the cause of error?\n",
    "In Figs. 2-3 we have the distributions of the number of OOVs in misclassified sentences and all the sentences respectively and in Figs. 4-5 we have the distributions of the number of PAD tokens in misclassified sentences and all the sentences respectively. From these Figures we see that the distributions are very similar which invites the conclusion that the number of OOVs or PAD tokens in a sentence does not play a significant role in the likelihood of it being misclassified.\n",
    "\n",
    "##### What words appear frequently in misclassified vs in all phrases?\n",
    "In Fig. 6 are shown the 10 most frequent words in misclassified sentences, in Fig. 7 are shown the 10 most frequent words all the sentences, and in Fig. 8 are shown the 10 words that appear the most in misclassified sentences relative their total appearance. So for instance we can see that  ~75% of the phrases the word \"trip\" appears in are misclassified. We can see here that words that often appear in misclassified examples tend to either be very common such as \"the\" or have more than one meaning such as \"trip\".\n",
    "\n",
    "\n",
    "##### For each sentence position in the initial paragraph, what is the likelihood of it being misclassified?\n",
    "In Figs. 9 to 13 are shown the confusion matrices for sentences 1 to 5 respectively. We can see that the mystakes of our model varies depending on which sentence it tries to classify. Nonetheless, a very apparent trend is that for all sentences, whenever their true position is at the start of the paragraph, the model overwhelmigly predicts this correctly.\n",
    "\n",
    "### Conclusion and Further Work\n",
    "In our approach, we experimented with various architectures of neural networks in order to solve the sentence ordering problem. Our best performing model used 200D Glove embeddings, two-layer bi-directional LSTMs with attention and CNNs for sentence embeddings and an MLP performing the classification task !!!!!!UPDAAAAATTTEEE!!!!!!!. Our final score on the development set was !!!!! PUT IITTTT !!!!. We believe that given more resources (especially a bigger liniency on memory allowed) our models would have achieved classifications comfortably above 60%, and hence are very satisfied with our project. \n",
    "\n",
    "Many thanks for Reading and Grading our Repors,\n",
    "All the best,\n",
    "Group 03 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion matrix (true order vs predicted order) is as follows:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAEYCAYAAAAH/d6fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqKwBGtERGEJ1oiIwv4vue146Jhslv0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9299a5a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 1              #######################\n",
    "###  Overall Confusion Matrix for our model  ####\n",
    "print(\"The Confusion matrix (true order vs predicted order) is as follows:\")\n",
    "with tf.Session() as sess:\n",
    "    # LOAD EARLY STOPPED MODEL\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.checkpoint')\n",
    "\n",
    "    # MAKE SURE IT GIVES THE SAME PREDICTIONS AS BEFORE\n",
    "    dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\n",
    "    dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\n",
    "   \n",
    "    \n",
    "    # CREATE THE CONFUSION MATRIX\n",
    "    cm_dev = create_confusion_matrix(dev_predicted, dev_orders)\n",
    "    util.plot_confusion_matrix_dict(cm_dev,90, outside_label=\"None\")\n",
    "########################################################################  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Cell aggregating the errors our model did\n",
    "Number_of_missclassified_exaples_to_display = 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # LOAD EARLY STOPPED MODEL\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.checkpoint')\n",
    "\n",
    "    # MAKE SURE IT GIVES THE SAME PREDICTIONS AS BEFORE\n",
    "    dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\n",
    "    dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\n",
    "    \n",
    "    #GET THE ERROR EXAMPLES\n",
    "    errors  = getErrors(data_dev,dev_orders,dev_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup cells for Figures 2-5\n",
    "# Get the number of OOV and PAD tokens in each missclassified phrase and display them as histograms\n",
    "stats = getPADandOOVHistogramsOnErrors(errors,dev_stories)\n",
    "## Get the histogram of number of OOV and PAD tokens in each phrase for the full dev set\n",
    "full_devset_stats = getFullPadandOOVHistorgrams(dev_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The histogram of the number of OOV tokens in missclassified phrases:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9294309438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 2              #######################\n",
    "print(\"The histogram of the number of OOV tokens in missclassified phrases:\")\n",
    "plot_histogram(stats,'OOV_hist')\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The histogram of the number of OOV tokens in all phrases:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQKS1GOGgCT1mCEgST1mCEhSj/1f350GnUManIYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92797a1a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 3              #######################\n",
    "print(\"The histogram of the number of OOV tokens in all phrases:\")\n",
    "plot_histogram(full_devset_stats,'OOV_hist')\n",
    "#######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The histogram of the number of padding tokens in missclassified phrases:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npM79f/cwPZlRA4aSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92796b4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 4              #######################\n",
    "print(\"The histogram of the number of padding tokens in missclassified phrases:\")\n",
    "plot_histogram(stats,'PAD_hist')\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The histogram of the number of padding tokens in all phrases:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktQxQ0CSOmYISFLH/j/mOpLmJghQcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f927959ea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 5              #######################\n",
    "print(\"The histogram of the number of padding tokens in all phrases:\")\n",
    "plot_histogram(full_devset_stats,'PAD_hist')\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of words in the missclassified phrases\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGX5JREFUeJzt3Xu0XlV97vHvQyLhZriYbUaahO7UbrWBowK7Ea8DpYV0\nYE2sCKECUdEMSwqttTISbYWeM2JTtSIcT2gjpgktkkakJoIgOaEIOgxhc80FQqIJJGkgG6iA6Akm\n/M4fc8asbPb1Xe/eG5zPZ4w93rXmmmvNufb7rvWsy3tRRGBmZmU6aLg7YGZmw8chYGZWMIeAmVnB\nHAJmZgVzCJiZFcwhYGZWMIeAmVnBHAJmZgVzCJiZFWzkcHegL2PGjInW1tbh7oaZ2SvKPffc82RE\ntPRV72UfAq2trXR0dAx3N8zMXlEkPdqfer4cZGZWMIeAmVnBHAJmZgVzCJiZFcwhYGZWMIeAmVnB\nHAJmZgVzCJiZFcwhYGZWsJf9J4braJ1z06C3sXX+GYPehpnZYPGZgJlZwRwCZmYF6zMEJC2StEvS\nui7lF0l6WNJ6SV+slM+VtFnSRkmnV8pPkrQ2T7tSkpq7KmZmNlD9ORNYDEytFkh6DzANeHNEHAd8\nOZdPBmYAx+V5FkgakWe7CvgE0Jb/DlimmZkNvT5DICLuAJ7uUvxnwPyI2J3r7Mrl04ClEbE7IrYA\nm4EpksYBoyNidUQEcA0wvVkrYWZmjWn0nsDrgXdJukvSDyT9fi4fD2yr1Nuey8bn4a7l3ZI0S1KH\npI7Ozs4Gu2hmZn1pNARGAscAJwOfAZY18xp/RCyMiPaIaG9p6fOHcczMrEGNhsB24IZI1gAvAmOA\nHcDESr0JuWxHHu5abmZmw6jREPgO8B4ASa8HDgaeBFYAMySNkjSJdAN4TUTsBJ6VdHI+YzgfWF67\n92ZmVkufnxiWdB1wCjBG0nbgUmARsCi/bfQFYGa+4bte0jJgA7AHmB0Re/OiLiS90+hQ4Ob8Z2Zm\nw6jPEIiIc3qYdG4P9ecB87op7wCOH1DvzMxsUPkTw2ZmBXMImJkVzCFgZlYwh4CZWcEcAmZmBXMI\nmJkVzCFgZlYwh4CZWcEcAmZmBXMImJkVzCFgZlYwh4CZWcEcAmZmBXMImJkVzCFgZlYwh4CZWcH6\nDAFJiyTtyr8i1nXapyWFpDGVsrmSNkvaKOn0SvlJktbmaVc284fpzcysMf05E1gMTO1aKGkicBrw\nWKVsMjADOC7Ps0DSiDz5KuATpN8dbutumWZmNrT6DIGIuAN4uptJlwOXAFEpmwYsjYjdEbEF2AxM\nkTQOGB0Rq/NvEV8DTK/dezMzq6WhewKSpgE7IuKBLpPGA9sq49tz2fg83LW8p+XPktQhqaOzs7OR\nLpqZWT8MOAQkHQZ8Fvh887uTRMTCiGiPiPaWlpbBasbMrHgjG5jndcAk4IF8b3cCcK+kKcAOYGKl\n7oRctiMPdy03M7NhNOAzgYhYGxGvjYjWiGglXdo5MSIeB1YAMySNkjSJdAN4TUTsBJ6VdHJ+V9D5\nwPLmrYaZmTWiP28RvQ74MfAGSdslXdBT3YhYDywDNgC3ALMjYm+efCFwNelm8U+Am2v23czMaurz\nclBEnNPH9NYu4/OAed3U6wCOH2D/zMxsEPkTw2ZmBXMImJkVzCFgZlYwh4CZWcEcAmZmBXMImJkV\nzCFgZlYwh4CZWcEcAmZmBXMImJkVzCFgZlYwh4CZWcEcAmZmBXMImJkVzCFgZlYwh4CZWcH688ti\niyTtkrSuUvYlSQ9LelDSf0g6qjJtrqTNkjZKOr1SfpKktXnalflnJs3MbBj150xgMTC1S9lK4PiI\neBPwCDAXQNJkYAZwXJ5ngaQReZ6rgE+Qfne4rZtlmpnZEOszBCLiDuDpLmW3RsSePLoamJCHpwFL\nI2J3RGwh/Z7wFEnjgNERsToiArgGmN6slTAzs8Y0457Ax9j/o/HjgW2Vadtz2fg83LW8W5JmSeqQ\n1NHZ2dmELpqZWXdqhYCkzwF7gGub050kIhZGRHtEtLe0tDRz0WZmVjGy0RklfQR4H3BqvsQDsAOY\nWKk2IZftYP8lo2q5mZkNo4bOBCRNBS4B3h8Rv6hMWgHMkDRK0iTSDeA1EbETeFbSyfldQecDy2v2\n3czMaurzTEDSdcApwBhJ24FLSe8GGgWszO/0XB0Rn4yI9ZKWARtIl4lmR8TevKgLSe80OpR0D+Fm\nzMxsWPUZAhFxTjfF3+il/jxgXjflHcDxA+qdmZkNKn9i2MysYA4BM7OCOQTMzArmEDAzK5hDwMys\nYA4BM7OCOQTMzArmEDAzK5hDwMysYA4BM7OCOQTMzArmEDAzK5hDwMysYA4BM7OCOQTMzArmEDAz\nK1ifISBpkaRdktZVyo6RtFLSpvx4dGXaXEmbJW2UdHql/CRJa/O0K/PPTJqZ2TDqz5nAYmBql7I5\nwKqIaANW5XEkTQZmAMfleRZIGpHnuQr4BOl3h9u6WaaZmQ2xPkMgIu4Anu5SPA1YkoeXANMr5Usj\nYndEbAE2A1MkjQNGR8TqiAjgmso8ZmY2TBq9JzA2Inbm4ceBsXl4PLCtUm97Lhufh7uWm5nZMKp9\nYzgf2UcT+vJrkmZJ6pDU0dnZ2cxFm5lZRaMh8ES+xEN+3JXLdwATK/Um5LIdebhrebciYmFEtEdE\ne0tLS4NdNDOzvjQaAiuAmXl4JrC8Uj5D0ihJk0g3gNfkS0fPSjo5vyvo/Mo8ZmY2TEb2VUHSdcAp\nwBhJ24FLgfnAMkkXAI8CZwFExHpJy4ANwB5gdkTszYu6kPROo0OBm/OfmZkNoz5DICLO6WHSqT3U\nnwfM66a8Azh+QL0zM7NB5U8Mm5kVzCFgZlYwh4CZWcEcAmZmBXMImJkVzCFgZlYwh4CZWcEcAmZm\nBXMImJkVzCFgZlYwh4CZWcEcAmZmBXMImJkVzCFgZlYwh4CZWcEcAmZmBasVApI+JWm9pHWSrpN0\niKRjJK2UtCk/Hl2pP1fSZkkbJZ1ev/tmZlZHwyEgaTxwMdAeEccDI4AZwBxgVUS0AavyOJIm5+nH\nAVOBBZJG1Ou+mZnVUfdy0EjgUEkjgcOA/wKmAUvy9CXA9Dw8DVgaEbsjYguwGZhSs30zM6uh4RCI\niB3Al4HHgJ3AMxFxKzA2Inbmao8DY/PweGBbZRHbc5mZmQ2TOpeDjiYd3U8Cfgs4XNK51ToREUA0\nsOxZkjokdXR2djbaRTMz60Ody0F/AGyJiM6I+BVwA/B24AlJ4wDy465cfwcwsTL/hFz2EhGxMCLa\nI6K9paWlRhfNzKw3dULgMeBkSYdJEnAq8BCwApiZ68wElufhFcAMSaMkTQLagDU12jczs5pGNjpj\nRNwl6XrgXmAPcB+wEDgCWCbpAuBR4Kxcf72kZcCGXH92ROyt2X8zM6uh4RAAiIhLgUu7FO8mnRV0\nV38eMK9Om2Zm1jz+xLCZWcEcAmZmBXMImJkVzCFgZlYwh4CZWcFqvTvIetY656ZBb2Pr/DMGvQ0z\n+83mMwEzs4I5BMzMCuYQMDMrmEPAzKxgDgEzs4I5BMzMCuYQMDMrmEPAzKxgDgEzs4I5BMzMClYr\nBCQdJel6SQ9LekjS2yQdI2mlpE358ehK/bmSNkvaKOn0+t03M7M66p4JXAHcEhFvBN5M+o3hOcCq\niGgDVuVxJE0GZgDHAVOBBZJG1GzfzMxqaDgEJB0JvBv4BkBEvBARPwOmAUtytSXA9Dw8DVgaEbsj\nYguwGZjSaPtmZlZfnTOBSUAn8C+S7pN0taTDgbERsTPXeRwYm4fHA9sq82/PZWZmNkzqhMBI4ETg\nqog4AXiefOlnn4gIIAa6YEmzJHVI6ujs7KzRRTMz602dENgObI+Iu/L49aRQeELSOID8uCtP3wFM\nrMw/IZe9REQsjIj2iGhvaWmp0UUzM+tNwyEQEY8D2yS9IRedCmwAVgAzc9lMYHkeXgHMkDRK0iSg\nDVjTaPtmZlZf3V8Wuwi4VtLBwE+Bj5KCZZmkC4BHgbMAImK9pGWkoNgDzI6IvTXbNzOzGmqFQETc\nD7R3M+nUHurPA+bVadPMzJrHnxg2MyuYQ8DMrGAOATOzgjkEzMwK5hAwMyuYQ8DMrGAOATOzgjkE\nzMwK5hAwMyuYQ8DMrGAOATOzgjkEzMwK5hAwMytY3a+Stpeh1jk3DXobW+efMehtmNng85mAmVnB\nfCZgTeWzELNXltpnApJGSLpP0o15/BhJKyVtyo9HV+rOlbRZ0kZJp9dt28zM6mnG5aC/AB6qjM8B\nVkVEG7AqjyNpMjADOA6YCiyQNKIJ7ZuZWYNqhYCkCcAZwNWV4mnAkjy8BJheKV8aEbsjYguwGZhS\np30zM6un7pnAV4FLgBcrZWMjYmcefhwYm4fHA9sq9bbnMjMzGyYNh4Ck9wG7IuKenupERADRwLJn\nSeqQ1NHZ2dloF83MrA91zgTeAbxf0lZgKfBeSf8GPCFpHEB+3JXr7wAmVuafkMteIiIWRkR7RLS3\ntLTU6KKZmfWm4RCIiLkRMSEiWkk3fG+LiHOBFcDMXG0msDwPrwBmSBolaRLQBqxpuOdmZlbbYHxO\nYD6wTNIFwKPAWQARsV7SMmADsAeYHRF7B6F9MzPrp6aEQETcDtyeh58CTu2h3jxgXjPaNDOz+vy1\nEWZmBXMImJkVzCFgZlYwh4CZWcEcAmZmBXMImJkVzCFgZlYwh4CZWcH8y2L2G8O/amY2cD4TMDMr\nmEPAzKxgDgEzs4I5BMzMCuYQMDMrmEPAzKxgDgEzs4LV+aH5iZL+U9IGSesl/UUuP0bSSkmb8uPR\nlXnmStosaaOk05uxAmZm1rg6ZwJ7gE9HxGTgZGC2pMnAHGBVRLQBq/I4edoM4DhgKrBA0og6nTcz\ns3rq/ND8zoi4Nw8/BzwEjAemAUtytSXA9Dw8DVgaEbsjYguwGZjSaPtmZlZfU+4JSGoFTgDuAsZG\nxM486XFgbB4eD2yrzLY9l5mZ2TCpHQKSjgC+DfxlRDxbnRYRAUQDy5wlqUNSR2dnZ90umplZD2qF\ngKRXkQLg2oi4IRc/IWlcnj4O2JXLdwATK7NPyGUvERELI6I9ItpbWlrqdNHMzHpR591BAr4BPBQR\nX6lMWgHMzMMzgeWV8hmSRkmaBLQBaxpt38zM6qvzVdLvAM4D1kq6P5d9FpgPLJN0AfAocBZARKyX\ntAzYQHpn0eyI2FujfTMzq6nhEIiIHwLqYfKpPcwzD5jXaJtmZtZc/sSwmVnBHAJmZgVzCJiZFcwh\nYGZWMIeAmVnBHAJmZgVzCJiZFcwhYGZWMIeAmVnBHAJmZgVzCJiZFcwhYGZWMIeAmVnB6nyVtJll\nrXNuGvQ2ts4/Y9DbsPL4TMDMrGA+EzB7hfNZiNUx5CEgaSpwBTACuDoi5g91H8ysORxAr3xDejlI\n0gjg/wB/BEwGzpE0eSj7YGZm+w31PYEpwOaI+GlEvAAsBaYNcR/MzCwb6stB44FtlfHtwFuHuA9m\n9hvAl6KaQxExdI1JZwJTI+Ljefw84K0R8edd6s0CZuXRNwAbh6iLY4Anh6gtt/3yaN9tu+3f1LZ/\nOyJa+qo01GcCO4CJlfEJuewAEbEQWDhUndpHUkdEtA91uyW3Pdztu223XULbvRnqewJ3A22SJkk6\nGJgBrBjiPpiZWTakZwIRsUfSnwPfJ71FdFFErB/KPpiZ2X5D/jmBiPge8L2hbrefhvwSlNse9vbd\nttsuoe0eDemNYTMze3nxdweZmRWs6BCQdJSkC4ewvVZJ64awvYMlfVXSZkmbJC2XNKEyfUIu2yTp\nJ5KuyPMcJukpSaO7LO87ks6u0Z+LJT0k6do661WXpK1NXl636yWpXdKVTWrjI5K+1oxl5eUd8NqX\ndIqkG3uoe/VgfbJf0vSX07cGSNoqacxw92MoFR0CwFHAkIVAHZL6df8m78QPz6NfAF4NvCEi2oDv\nADcoA24AvpOnvR44ApgXEb8g3bz/QGW5RwLvBL4r6UhJjbx2LgT+MCI+3I/1eCV9ueFL1kvSyIjo\niIiLh7Ffven3az8iPh4RG5rdgfwcTyd9hcwrVv46nMFY7tBsAxFR7B/payt+CdwPfCn/rQPWAmcP\nQnutwEPA14H1wK3AocDrgFuAe4A7gTfm+ouBfwLuAr7Sx7J/D/hHYAtwAnAY8BQwuku9O4FT898d\nXaaNzvMcBvwxcHNl2keAa/PwGcAm4DLg2H6u+z8BL+T/7adJgfQgsBp4U65zGfCvwI+A6wbxeb87\nP44D7sjP/zrgXQ0sq7pez1T7D5wC3JjrHQ4sAtYA9wHTKv/XG/Lzvwm4HLgJeID0ifr/Ah4mfcjo\nqbyMUXnercDf5/53ACeSwvsnwCcrffwM6e3ZDwJ/18Nr/xTgduD63N617L9neDvQnod/DszL/VsN\ntOf6y/PyngHmA7tzm+tIN0Sry/pq7u/ngKdJr9n7SdvBvZV+t1XHa25LLcC3c5/uBt6Ry1+T510P\nXA08SvpQ1+H5ediQ1+XO3N71pO1jK/APwL2kt7r3tQ13AI8A76v0/848/73A23P5Kbl8BfBILjuX\n9Lq5H/hnYERTt4fB2tBeCX/5iViXhz8IrCS9dXUs8BgwbhDa2wO8JY8vy0/wKqAtl70VuK3yArqx\npyc9v1A/Cvww/10AvDpPexNwXzfzXA5cnP8u72b6fXneg4EngNfk8lv2vYDz+BjgU/mFeQvwIeDg\nPtZ/a57vfwOX5rL3Avfn4cvyRnToED3/nwY+l4dH7PvfNbCcfet1QP85MAS+AJybh4/KO4TDSSHw\nU+BI4BCgE/gmKaAeA36H9FUr9wBfA64B/rLS7p9VntcHSWd+LcATufw08k6YdOZ/I/BuKq/9Sl+f\nIX2A8yDgx8A787Tb2R8CAfxxHv4i8OVc9iPgHFJIXQ/8vLLsf63MczuwoDJtMXBmZfw/2b99fAG4\nqEnb0jcr63Ms8FAevhL4fB4+I6/LGNL+4Ou5nQBOy3UWAX+d//eXVPrT2zZ8S/6ftpGC/RBSkByS\n67QBHZXn4XlgUh7/PeC7wKvy+ALg/GZuB6+kU+7B9k7S0ede4AlJPwB+n+Z/mG1LRNyfh+8hvcje\nDnwrXaEBYFSl/rdyn7qzk7ThfzwiHm5mJyPiBUkrgDMlfZt0dvH9yvQnSTueyyW9jbRx/C0pQPry\nTtJGRkTcJuk1lfsPKyLil01cld7cDSyS9CrSZbH7+5qhH3rq/2nA+yX9dR4/hLQzAlgVEc8ASNoA\nvIf0bbsbSDv1LaQd6+uBJcBs0tE07H99rgWOiIjngOck7ZZ0VG73NFK4Q7rk10YKmK7WRMT23I/7\nSa/NH3ap8wIpSCC9fj9ACqk3At8iHTj8FTBC0l2knd0xpCPt7+b5/r2btve5GviopL8CziZ96WRP\nBrIt/QEwuVI+WtIRpED8E4CIuEnSf+fpa0ln1nuAXRFxay7/N9IB1K/XIy+nt214WUS8CGyS9FPS\n/2oL8DVJbwH2kp7bfdZExJY8fCpwEnB3XvahwK5e/icD5hAYersrw3tJZx0/i4i39FD/+V6WdSbp\n6P8GSUuBJRHxaJ72E+BYSa/OO4Z9TiJtxMrz/1reER8LbM5F15F27AKWR8SvutSfTDoTmQ78gHTk\nVFdv69tUEXGHpHeTjgAXS/pKRFxTc7E99V/AByPigO/BkvRWDnxNPEf63qz3ko6sp/fR3r55X+yy\nnBdJ27eAv4+If+7Sbmsvy4L02uxu//CryIeklTpd32cepJ3gmRGxTdJlpNDbp7fn+NvApcBtwD0R\n8VQvdQeyLR0EnBwR/69aWNlpH7gCEY9IOhE4HzhS0ucj4n/um9xlPQ7qpd1q/er4p0iB+eY8f7Vf\n1f+PSNv13B6WXVvpN4afIx1pQboOd7akEZJaSEcIa4agD88CWyR9CCDfs31zf2aMiFsj4mzgXaRT\n+eWS/q+k1oh4nnTU+JV9N64knU86MruNdPp6WC7bd3PrH4HFkW4MQzp1byMdeV63r11JJ0paTTpq\nexg4IdLNw7v6uc53Ah/OyzoFeDIinu3nvE0j6bdJl02+TlqXEwexue8DF+Ub8kg6oYd6o0g7ty+S\nts99l27Oy9PPIwXuQNr9WD5aRdJ4Sa/lwNd+XceSXgcfBP6U/Tu0J3O7Z/Y0Y9d+5J3094GrgH8Z\nYD9625ZuBS7aVzEfgUO6J/SnueyPgKPz8G8BvyDduxpFOiIn1z3g7Ci/dnvbhj8k6SBJryNd3ttI\nuvy3M58hnEe6HNmdVaSz8dfmZR+TX7dNU3QI5KOMHym9bfNtpEsrD5B2kpdExOND1JUPAxdIeoB0\n2jyg31iIiKci4op8JPJZ0lERwFzSBvmIpE2k6/YfiIx0Kv+hPO2RXPezleW+SLoM8RoO3PH8Evho\nRLw9Ir4RET8f4PpeBpwk6UHSTcSZA5y/WU4BHpB0H+nSwxWD2Nb/Al4FPChpfR7vzmjSDvBm0hHh\n75J2RpNIZwYvkm409ku+jPFN4MeS1pKez1dXX/uSvtTYKv3aRtKN68Wk19g20g3kdaQd+t29zLsU\n+Iyk+/JOEtJN6RdJO+6B6mlbuhhol/RgvuT2yVz+d8C783PyJ+y/TPY/SAeB3yNtF89LeogUElcN\noF3yMteQntNP5qBbAMzM9d9ID2dHkd6V9TfArXl7WUm6X9Q0/sSwmTUsX1a6kXTt/pcREZJmAOdE\nREM/GJXvmxwZEX/btI42aN/6RcTxDc6/OM9/fRO71VS+J2BmzXAS6UangJ8BH2tkIZL+g/R2y/c2\nsW/WC58JmJkVrOh7AmZmpXMImJkVzCFgZlYwh4CZWcEcAmZmBXMImJkV7P8DdiINxaTs8I4AAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f927959ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 6              #######################\n",
    "#Get the frequency of the words in the missclassified phrases and plot it\n",
    "word_freq = getErrorWordFrequency(errors,dev_stories,vocab)\n",
    "print(\"Frequency of words in the missclassified phrases\")\n",
    "plot_word_histogram(word_freq,10,['<PAD>','.'])\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency of words in all phrases\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9279646eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 7              #######################\n",
    "#Get the full frequency of words in the dev set and plot it \n",
    "norma_freq=getWordFrequency(dev_stories,vocab)\n",
    "print(\"frequency of words in all phrases\")\n",
    "plot_word_histogram(norma_freq,10,['<PAD>','.'])\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of word frequencies missclassified/total\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92795a50b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 8              #######################\n",
    "#Get the ratio of the number of times a word occurs in missclassified exampled\n",
    "#vs the total number of times the word appears and plot it\n",
    "freq_hist = freq_ratios(norma_freq,word_freq)\n",
    "print(\"Ratio of word frequencies missclassified/total\")\n",
    "plot_word_histogram(freq_hist,10,['<PAD>','.'])\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cell for Figs. 9-13\n",
    "#### GET THE CONFUSION MATRIX FOR EACH SENTENCE SEPARATELY ########\n",
    "with tf.Session() as sess:\n",
    "    # LOAD EARLY STOPPED MODEL\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './model/model.checkpoint')\n",
    "\n",
    "    # MAKE SURE IT GIVES THE SAME PREDICTIONS AS BEFORE\n",
    "    dev_feed_dict = {story: dev_stories, order: dev_orders, dropout_prob: 0.0, phase: False}\n",
    "    dev_predicted = sess.run(predict, feed_dict=dev_feed_dict)\n",
    "   \n",
    "    # CREATE THE CONFUSION MATRIX PER SENTENCE\n",
    "    confusion_per_sentence = []\n",
    "    for sentence in range(5):\n",
    "        confusion_per_sentence.append(create_confusion_matrix_for_sentence(dev_predicted, dev_orders,sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion matrix (true order vs predicted order) for sentence 0 is as follows:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEYCAYAAAAK467YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJWkgA1SSBjJAJWmg/w+pcauMr7AoKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92792a8470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 9              #######################\n",
    "print(\"The Confusion matrix (true order vs predicted order) for sentence 0 is as follows:\")\n",
    "util.plot_confusion_matrix_dict(confusion_per_sentence[0],90, outside_label=\"None\")\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion matrix (true order vs predicted order) for sentence 1 is as follows:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEYCAYAAAAK467YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBqgkdWSASlJHBqgkdfT/ADNgz32/UTqEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92785981d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 10              #######################\n",
    "print(\"The Confusion matrix (true order vs predicted order) for sentence 1 is as follows:\")\n",
    "util.plot_confusion_matrix_dict(confusion_per_sentence[1],90, outside_label=\"None\")\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion matrix (true order vs predicted order) for sentence 2 is as follows:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAEYCAYAAADcRnS9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFYJJREFUeJzt3V2wXeV93/HvT+LFEJMaLKyRJWxII6cBtxGtRknHbcbB\ndZEdT7AvyoiZ2kzLDL4gLp7xtIH0ws5kNOMLO26msd3KMTVJU4jixAPDuM5gguu6tQFBFYx4qdUA\nQap4kV8GiLEciX8v9jr1jqxzzt6Lvc9a65zvh1lz9n72Xs96DoKf/utZb6kqJEnTWdf1ACRpiAxP\nSWrB8JSkFgxPSWrB8JSkFgxPSWrB8JS06iR5VZJ7k/x5kgNJfqNp/0iSw0n2N8s7x9a5McnBJI8l\nuXzZbXiep6TVJkmAn6iqF5OcDnwNuB7YCbxYVR876fsXA7cAO4DXA18G3lRVJxbbhpWnpFWnRl5s\n3p7eLEtVilcAt1bVsap6HDjIKEgXddpMRnqSnHZW5Yxz5tH1itr2s2/oeggak64HMCMnVsHe3lN/\n+STfPnp0Zn8k63/yjVXHX5pqnXrpuQPAD8aa9lTVnoU3SdYD9wM/DXyyqu5J8g7gA0neB+wDPlRV\n3wU2A98Y6+tQ07ao+YTnGedw5s9cOY+uV9R///q/73oIM7FapmZOW786dpRe/MHxrofwiv2TX/z5\nmfZXx1+aOjN+sP+TP6iq7Yv2Odrl3pbkNcAXkrwZ+DTwm4yq0N8EPg78yzZjXh3/NUoauEDWTbdM\nqKq+B9wN7KyqZ6rqRFW9DHyGH+2aHwYuGFttS9O2KMNTUvcCJNMtS3WXnN9UnCQ5C3g78GiSTWNf\new/wUPP6dmBXkjOTXARsBe5dahtz2W2XpKlNUU1OYBNwczPvuQ7YW1V3JPn9JNsY7bY/AbwfoKoO\nJNkLPAwcB65b6kg7GJ6S+mKZanIaVfUgcOkp2t+7xDq7gd2TbsPwlNQDmXXlOXeGp6R+mGHluRIM\nT0ndC1aekjS95Y+g943hKakfrDwlqQUrT0malkfbJWl6C1cYDYjhKakfrDwlaVqB9eu7HsRUDE9J\n3fM8T0lqyTlPSZqWR9slqR0rT0lqwcpTkqY0wd3h+2aiqE+ys3kQ/MEkN8x7UJLWoDk9w2helh1B\ncxv7TwLvAC4GrmoeEC9JszPDZxithEniewdwsKr+oqp+CNzK6AHxkjQj83t65rxMMoLNwFNj70/5\nMPgk1ybZl2TftA+vl6ShVZ4zO2BUVXuAPQDrzn5dzapfSWvAKr3CaOqHwUvSdIZ3kvwko70P2Jrk\noiRnALsYPSBekmZnte22V9XxJL8K/CmwHripqg7MfWSS1paBVZ4TzXlW1ReBL855LJLWsh5Uk9Pw\nCiNJ3cvw5jwNT0n9MLDKc1hRL2nVSjLVskxfr0pyb5I/T3IgyW807ecluTPJt5qf546tc2NzCfpj\nSS5fbryGp6TOjZ7/NrvwBI4Bl1XVzwHbgJ1JfgG4AbirqrYCdzXvaS453wVcAuwEPtVcmr4ow1NS\n99JiWUKNvNi8Pb1ZitGl5Tc37TcD725eXwHcWlXHqupx4CCjS9MXZXhK6oHpqs4JKk+SrE+yH3gW\nuLOq7gE2VtWR5itPAxub1xNdhj7OA0aSemGSQDzJhiT7xt7vaS4TB6CqTgDbkrwG+EKSN4+vXFWV\npPWl5IanpF5oEZ5Hq2r7cl+qqu8luZvRXOYzSTZV1ZEkmxhVpdDiMnR32yX1woyPtp/fVJwkOQt4\nO/Aoo0vLr26+djVwW/P6dmBXkjOTXARsBe5dahtWnpK6N8FBoCltAm5ujpivA/ZW1R1Jvg7sTXIN\n8CRwJUBVHUiyF3gYOA5c1+z2L8rwlNS5MNlBoElV1YPApado/zbwtkXW2Q3snnQbhqekXphleK4E\nw1NSLxiektSC4SlJ05r9AaO5Mzwl9YKVpyRNadZH21eC4SmpFwxP4NKffQP/457fmUfXK+pz9z3R\n9RBm4rKLXtf1EGbivFef0fUQZuLsM5a809kgrJtH0A0rO608JfVArDwlqZV164Z1qw3DU1LnPGAk\nSW0NKzsNT0k94JynJLVjeEpSC4anJLUxrOw0PCX1g5WnJE1p0scJ94nhKakXDE9JasHwlKQ2hpWd\nhqekfrDylKRpeYWRJE0vwMCy0/CU1AeeqiRJrQwsOw1PSf1g5SlJ08rwKs9h3fde0qoUYN26TLUs\n2V9yQZK7kzyc5ECS65v2jyQ5nGR/s7xzbJ0bkxxM8liSy5cbs5WnpF6YceV5HPhQVT2Q5Bzg/iR3\nNp99oqo+9je3nYuBXcAlwOuBLyd5U1WdWGwDy1aeSW5K8mySh1r/GpK0jIWbg0y6LKWqjlTVA83r\nF4BHgM1LrHIFcGtVHauqx4GDwI6ltjHJbvvngJ0TfE+S2mnmPKdZgA1J9o0t156y6+RC4FLgnqbp\nA0kebArDc5u2zcBTY6sdYumwXT48q+qrwHeW+54ktTU6SX7qyvNoVW0fW/b8WL/Jq4E/Bj5YVc8D\nnwZ+CtgGHAE+3nbMMztglOTahb8Bnjv63Ky6lbQmTBeck5zWlOR0RsH5B1X1JwBV9UxVnaiql4HP\n8KNd88PABWOrb2naFjWz8KyqPQt/A5y/4fxZdStpjWix275EXwnwWeCRqvqtsfZNY197D7BwLOd2\nYFeSM5NcBGwF7l1qGx5tl9QLMz5J/i3Ae4FvJtnftP06cFWSbUABTwDvB6iqA0n2Ag8zOlJ/3VJH\n2sHwlNQHMz5Jvqq+xqnvEPrFJdbZDeyedBuTnKp0C/B14GeSHEpyzaSdS9IkWh4w6tSylWdVXbUS\nA5G0tvUgD6fibrukXuhDNTkNw1NSLwwsOw1PST3gYzgkaXo+hkOSWunHEfRpGJ6SemFg2Wl4SuqB\nsOwNjvvG8JTUuYWT5IfE8JTUC4anJLUwsOw0PCX1g5WnJE1rgI8eNjwldS6e5ylJ7QwsOw1PSf2w\nbmDpaXhK6oWBZafhKal78a5KktTOwK7OnE94Hn+5+PYLx+bR9Yr65pHvdz2Emfi/zx/qeggz8dcn\nqushzMTOvz38R3P/1bHjM+/TylOSWhhYdhqekroXRud6DonhKakXnPOUpGn15Fns0zA8JfXCwLLT\n8JTUvTC8K4zWdT0ASYKFE+UnX5buKxckuTvJw0kOJLm+aT8vyZ1JvtX8PHdsnRuTHEzyWJLLlxuv\n4SmpF9LMe066LOM48KGquhj4BeC6JBcDNwB3VdVW4K7mPc1nu4BLgJ3Ap5KsX2oDhqekzk1bdS6X\nnVV1pKoeaF6/ADwCbAauAG5uvnYz8O7m9RXArVV1rKoeBw4CO5bahnOeknqhxZznhiT7xt7vqao9\nJ38pyYXApcA9wMaqOtJ89DSwsXm9GfjG2GqHmrZFGZ6SeqHF4aKjVbV9yT6TVwN/DHywqp4f392v\nqkrS+ppfw1NSL8z6PM8kpzMKzj+oqj9pmp9JsqmqjiTZBDzbtB8GLhhbfUvTtijnPCV1bnSq0nTL\nkv2NkvizwCNV9VtjH90OXN28vhq4bax9V5Izk1wEbAXuXWobVp6Sujf7K4zeArwX+GaS/U3brwMf\nBfYmuQZ4ErgSoKoOJNkLPMzoSP11VXViqQ0YnpJ6YZbZWVVfY/Fp1Lctss5uYPek2zA8JfWC17ZL\n0pQW5jyHxPCU1AtWnpLUwrCi0/CU1APJ8O6qZHhK6oWBZafhKakfVt2cZ5ILgN9jdAF9Mbr4/rfn\nPTBJa0cI6wd2uH2SynPhvngPJDkHuD/JnVX18JzHJmmtmOA2c32zbHg2t2860rx+IcnCffEMT0kz\ns+p228eddF+8kz+7FrgWYPOWC07+WJKWNLS7FE083pPvi3fy51W1p6q2V9X21244f5ZjlLTKhZk/\nhmPuJqo8F7kvniTNzMCOF010tH2x++JJ0swMLTwn2W1fuC/eZUn2N8s75zwuSWvI6KFuq2y3fZn7\n4knSTAyt8vQKI0m90INiciqGp6TOje7nOaz0NDwl9cLQzvM0PCX1wsAKT8NTUveSuNsuSW0MLDsN\nT0n94KlKkjQlj7ZLUksDy07DU1IPxN12SWolA7sKfGjnpUpahUZzntMty/aZ3JTk2SQPjbV9JMnh\nU93kKMmNSQ4meSzJ5cv1b+UpqRfmsNv+OeB3GD3Actwnqupj4w1JLgZ2AZcArwe+nORNVXVisc6t\nPCX1wqxvSVdVXwW+M+HmrwBurapjVfU4cBDYsdQKhqekzrXcbd+QZN/Ycu2Em/tAkgeb3fpzm7bN\nwFNj3znUtC3K8JTUvSzcEHnyBTi68Ny0ZtkzwZY+DfwUsI3RU4E/3nbIznlK6oWVOEm+qp5ZeJ3k\nM8AdzdvDwPhjf7c0bYuy8pTUuXkcbT/ldpJNY2/fAywcib8d2JXkzCQXAVuBe5fqay6V52nrwmvP\nOXMeXa+oD/3ji7oewkyceLm6HsJMfOfFH3Y9hJm44LVndz2EV+xVp6+feZ+zLjyT3AK8ldHc6CHg\nw8Bbk2wDCngCeD9AVR1Ishd4GDgOXLfUkXZwt11SL4R1Mz5JvqquOkXzZ5f4/m5g96T9G56SOhe8\ntl2Spue17ZLUjrekk6QpudsuSS1ZeUpSCwPLTsNTUvfC8K7YMTwldS/utkvS1HwAnCS1NKzoNDwl\n9cTACk/DU1IfTHZ3+D4xPCV1zqPtktSSlacktTCs6DQ8JfVBrDwlaWrOeUpSS1aektTCsKLT8JTU\nEwMrPA1PSd0bzXkOKz2XDc8krwK+CpzZfP/zVfXheQ9M0tqyGivPY8BlVfViktOBryX5r1X1jTmP\nTdKaEbLaKs+qKuDF5u3pzVLzHJSktWdoledEp1YlWZ9kP/AscGdV3XOK71ybZF+Sfc8dfW7W45S0\nii3MeU6zdG2i8KyqE1W1DdgC7Ejy5lN8Z09Vba+q7edvOH/W45S0mmVUeU6zdG2qk/qr6nvA3cDO\n+QxH0lq16sIzyflJXtO8Pgt4O/DovAcmaW3JlP8s219yU5Jnkzw01nZekjuTfKv5ee7YZzcmOZjk\nsSSXL9f/JJXnJuDuJA8C9zGa87xjgvUkaSKjZxhNt0zgc/z4XvINwF1VtRW4q3lPkouBXcAlzTqf\nSrJ+qc4nOdr+IHDpREOVpJZmfapSVX01yYUnNV8BvLV5fTPwFeDXmvZbq+oY8HiSg8AO4OuL9e8V\nRpJ6ocU85oYk+8be76mqPcuss7GqjjSvnwY2Nq83A+Pnrh9q2hZleErqhRaV59Gq2t52e1VVSVqf\ns254SurcwpznCngmyaaqOpJkE6Nz1wEOAxeMfW9L07aood1/VNKqNO2x9tZJeztwdfP6auC2sfZd\nSc5MchGwFbh3qY6sPCV1bw7nbia5hdHBoQ1JDgEfBj4K7E1yDfAkcCVAVR1Ishd4GDgOXFdVJ5bq\n3/CU1Auz3muvqqsW+ehti3x/N7B70v4NT0mdG8159uCyoSkYnpJ6YVjRaXhK6ouBpafhKakXVt3N\nkCVpJQxsytPwlNQPA8tOw1NSTwwsPQ1PSZ1LPFVJkloZVnQanpL6YmDpaXhK6oFV+Nx2SVoJA5vy\nnE94FvDyy63vMdobZ5+x5CNMBuP7P1zy5jCDMbQDCov5D/c80fUQXrHn/urYTPsLg9trt/KU1BMD\nS0/DU1IvOOcpSS0MbVbG8JTUCwPLTsNTUg8M8IiR4SmpF5zzlKQpBec8JamVgWWn4SmpJwaWnoan\npF5wzlOSWnDOU5JaGFh2Gp6SemJg6Wl4Surc6Bz5YaWn4Smpe5n9nGeSJ4AXgBPA8aranuQ84A+B\nC4EngCur6rtt+l83m2FK0iuTKZcJ/VJVbauq7c37G4C7qmorcFfzvhXDU1I/zCk9T3IFcHPz+mbg\n3W07Mjwl9UCm/mcCBXw5yf1Jrm3aNlbVkeb108DGtiN2zlNSL7SY89yQZN/Y+z1VtWfs/T+qqsNJ\nXgfcmeTR8ZWrqpK0fl6Q4Smpcy33xI+OzWX+mKo63Px8NskXgB3AM0k2VdWRJJuAZ9uN2N12SX0x\nwznPJD+R5JyF18A/BR4Cbgeubr52NXBb2+FOXHkmWQ/sAw5X1bvablCSTmXG53luBL6Q0VzAacB/\nqaovJbkP2JvkGuBJ4Mq2G5hmt/164BHgJ9tuTJIWM8vzPKvqL4CfO0X7t4G3zWIbE+22J9kC/DLw\nu7PYqCSdbGXOVJqdSSvPfwf8G+CcOY5F0lo1hyuM5m3ZyjPJu4Bnq+r+Zb53bZJ9SfYdPfrczAYo\naa0YVu05yW77W4Bfaa4TvRW4LMl/PvlLVbWnqrZX1fYNG86f8TAlrWYLzzCaZunasuFZVTdW1Zaq\nuhDYBfxZVf3zuY9M0poyrLrTk+Ql9UQfqslpTBWeVfUV4CtzGYmkNS0DS08rT0m9MKzoNDwl9UBf\nDgJNw/CU1As+hkOS2hhWdhqekvphYNlpeErqB+c8JWlqEz9aozcMT0mdW7g8c0i8k7wktWDlKakX\nhlZ5Gp6SesE5T0mallcYSdL0+nKbuWkYnpL6YWDpaXhK6gXnPCWpBec8JamFgWWn4SmpJwaWnoan\npF4Y2pxnqmr2nSbPAU/OvOMf2QAcnWP/K8Xfo1/8PSb3xqqa2TPGk3yJ0bincbSqds5qDNOaS3jO\nW5J9VbW963G8Uv4e/eLvoWl4YxBJasHwlKQWhhqee7oewIz4e/SLv4cmNsg5T0nq2lArT0nqlOEp\nSS0YnpLUguEpSS0M4vLMJH8HuALY3DQdBm6vqke6G9Xa1fx5bAbuqaoXx9p3VtWXuhvZdJLsAKqq\n7ktyMbATeLSqvtjx0FpL8ntV9b6ux7EW9P5oe5JfA64CbgUONc1bgF3ArVX10a7GNitJ/kVV/aeu\nxzGJJP8KuA54BNgGXF9VtzWfPVBVf7/L8U0qyYeBdzAqIO4Efh64G3g78KdVtbvD4U0kye0nNwG/\nBPwZQFX9yooPag0ZQnj+b+CSqvrrk9rPAA5U1dZuRjY7Sf6yqt7Q9TgmkeSbwD+sqheTXAh8Hvj9\nqvrtJP+rqi7tdIATan6PbcCZwNPAlqp6PslZjCrqv9fpACeQ5AHgYeB3gWIUnrcwKiyoqv/W3ehW\nvyHstr8MvJ4fv9HIpuazQUjy4GIfARtXciyv0LqFXfWqeiLJW4HPJ3kjw7qp2PGqOgF8P8n/qarn\nAarqpSRD+e9qO3A98G+Bf11V+5O8ZGiujCGE5weBu5J8C3iqaXsD8NPAr3Y2qultBC4HvntSe4D/\nufLDae2ZJNuqaj9AU4G+C7gJ+LvdDm0qP0xydlV9H/gHC41J/hYD+Uu5ql4GPpHkj5qfzzCM/6dX\nhd7/i66qLyV5E7CDv3nA6L6mchiKO4BXL4TOuCRfWfnhtPY+4Ph4Q1UdB96X5D92M6RWfrGqjsH/\nD6EFpwNXdzOkdqrqEPDPkvwy8HzX41krej/nKUl95HmektSC4SlJLRiektSC4SlJLfw/VJJkoS5U\nNqwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92784931d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 11              #######################\n",
    "print(\"The Confusion matrix (true order vs predicted order) for sentence 2 is as follows:\")\n",
    "util.plot_confusion_matrix_dict(confusion_per_sentence[2],90, outside_label=\"None\")\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion matrix (true order vs predicted order) for sentence 3 is as follows:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEYCAYAAAAK467YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGvp/8fJKPUl7aNcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92783a5fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 12              #######################\n",
    "print(\"The Confusion matrix (true order vs predicted order) for sentence 3 is as follows:\")\n",
    "util.plot_confusion_matrix_dict(confusion_per_sentence[3],90, outside_label=\"None\")\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion matrix (true order vs predicted order) for sentence 4 is as follows:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEYCAYAAAAK467YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFFVJREFUeJzt3X/sXfV93/Hnyw4QEshC6tRybBKo5jaDrjGt5aRim9JE\nGW5alfSPISMtQVskRxPtiBRtC90f6TR5yh9rsm5aqrkJC9vSUDc/hIVQIpeSoqgd4BBGMITFK1Bs\nGYhpOsJCSGze++MeR986/n6/557vud97zvf7fKCj772fe+857y+Yl9/nc37cVBWSpOltmHcBkjRW\nBqgkdWSASlJHBqgkdWSASlJHBqgkdWSASlJHBqgkdWSASlJHr5jFSvOKCyvnXzyLVa+qHX/njfMu\noReZdwE9WSvXzL28Bq7+e+ovn+S5kyd7/aO18TVvqjr1Yuv314vf/nJV7e6zhmnNJkDPv5gLfua6\nWax6Vd3zZ/9x3iX04hUb18aOxlq57PjFH5yedwkr9o6//9be11mnvs8Fb97T+v3f//p/2tR7EVOa\nSYBK0tQCZFz7SwaopOHIuPaWDFBJw2EHKkldxA5UkjqzA5WkDoIdqCR1EztQSerMDlSSOrIDlaQu\nPAovSd14JZIkrcDIOtBxVStpDWt24dsuy60teWWS+5L8ryRHkvybZvx1SQ4l+Vbz85IFn7k5ydEk\njyW5ZrltGKCShmND2i/Lewl4R1W9BdgB7E7yNuDDwF1VtR24q3lOkiuAPcCVwG7gE0k2Lllu519U\nkvp05kT6njrQmniheXpesxRwLXBrM34r8J7m8bXAbVX1UlU9DhwFdi21DQNU0nAk7RfYlOTwgmXv\nj68uG5M8CDwLHKqqe4HNVXWiecvTwObm8VbgqQUfP9aMLcqDSJIGYurTmE5W1c6l3lBVp4EdSV4L\nfDHJz571eiXpfKduO1BJwzFdB9paVf01cDeTuc1nkmyZbC5bmHSnAMeBSxd8bFsztigDVNJw9HsU\n/vVN50mSC4F3Ad8EDgI3NG+7Abi9eXwQ2JPkgiSXA9uB+5bahrvwkoahQ2e5jC3Arc2R9A3Agaq6\nI8mfAweSvB94ErgOoKqOJDkAPAKcAm5spgAW1SpAk+wGfhfYCHyyqj7a9TeSpEX1eCJ9VT0EXHWO\n8eeAdy7ymX3AvrbbWLbaJr3/M/DLwBXA9c35UpLUrxnNgc5Km7jfBRytqr+oqh8AtzE5X0qSetTv\nlUiroU0Vrc6NSrL3zPlYderFvuqTtJ6MrAPt7SBSVe0H9gNseNVPdj6vStI6tUa/0mPqc6MkaXrj\nux9om2rvB7YnuTzJ+Uwutj8427IkrUtrbRe+qk4l+Q3gy0xOY7qlqo7MvDJJ68/IOtBWc6BVdSdw\n54xrkbTeDaSzbMsrkSQNQ8Y3B2qAShoOO1BJ6iYGqCRNb/KlnAaoJE0vIe2+62gwDFBJg2EHKkkd\nGaCS1JEBKkldpFlGxACVNAghdqCS1JUBKkkdGaCS1JEBKkldeBBJkrqzA5WkDjwKL0krYIBKUlfj\nys/ZBOjPvflSDv3px2ex6lV19b+7e94l9OLdb9027xJ6cd2VW+ZdQi9e++rz513Cip1+eQYrjR2o\nJHVmgEpSRwaoJHXgUXhJWolx5Sfj+g5RSWtXcxCp7bLs6pJLk9yd5JEkR5Lc1Iz/dpLjSR5slncv\n+MzNSY4meSzJNcttww5U0mD0vAt/CvhQVT2Q5GLga0kONa99vKr+/VnbvgLYA1wJvAH44yQ/XVWn\nF9uAHaikweizA62qE1X1QPP4u8CjwNYlPnItcFtVvVRVjwNHgV1LbcMAlTQcmWKBTUkOL1j2Lrra\n5DLgKuDeZug3kzyU5JYklzRjW4GnFnzsGEsHrgEqaTim7EBPVtXOBcv+RdZ5EfB54INV9Tzwe8BP\nATuAE8DvdK3XOVBJg9B213zKdZ7HJDw/U1VfAKiqZxa8/vvAHc3T48ClCz6+rRlblB2opMHo+Sh8\ngE8Bj1bVxxaML7wm+NeBh5vHB4E9SS5IcjmwHbhvqW3YgUoajJ470KuB9wLfSPJgM/ZbwPVJdgAF\nPAF8AKCqjiQ5ADzC5Aj+jUsdgQcDVNKQ9JifVfXVRdZ45xKf2Qfsa7sNA1TSYHgppyR14e3sJKmb\nACPLTwNU0lB4NyZJ6mxk+WmAShoOO1BJ6iJ2oJLUSYANG8aVoAaopMEYWwe67LXwze2enk3y8HLv\nlaSV6PNa+NXQ5mYinwZ2z7gOSetdMwfadhmCZXfhq+qe5makkjQzIWzYMK4bxPVWbZK9Z+4M/dzJ\nk32tVtI6MrYOtLcArar9Z+4M/RObNvW1WknryNjmQD0KL2kYBtRZtmWAShqEyc1ExpWgbU5j+izw\n58DPJDmW5P2zL0vSejS2OdA2R+GvX41CJGlsHai78JIGY2T5aYBKGgjvSC9J3XhHeknqbDjnd7Zl\ngEoajJHlpwEqaTjsQCWpiwGd39mWASppEMZ4JZIBKmkwDFBJ6mhk+WmAShoOO1BJ6mKEB5HGdf98\nSWtWaH8z5TadapJLk9yd5JEkR5Lc1Iy/LsmhJN9qfl6y4DM3Jzma5LEk1yy3DQNU0mD0fDu7U8CH\nquoK4G3AjUmuAD4M3FVV24G7muc0r+0BrmTyRZqfSLJxqQ0YoJIGY0PSellOVZ2oqgeax98FHgW2\nAtcCtzZvuxV4T/P4WuC2qnqpqh4HjgK7ltqGc6CSBmPKOdBNSQ4veL6/qvafe725DLgKuBfYXFUn\nmpeeBjY3j7cC/3PBx441Y4syQCUNQqa/nd3Jqtq5/HpzEfB54INV9fzCbVRVJampi20YoJIGY0PP\nR+GTnMckPD9TVV9ohp9JsqWqTiTZAjzbjB8HLl3w8W3N2KJmFqAb+v43MQcH/tkvzruEXjz8zP+d\ndwm9+H8vnZ53Cb245NXzrmDlZvV/d5/ngWaysk8Bj1bVxxa8dBC4Afho8/P2BeN/kORjwBuA7cB9\nS23DDlTSYPR8HujVwHuBbyR5sBn7LSbBeaD5gswngesAqupIkgPAI0yO4N9YVUv+rW2AShqEMDkX\ntC9V9VUWb5bfuchn9gH72m7DAJU0GGOb+TNAJQ1DyyuMhsQAlTQYI8tPA1TSMARaXWE0JAaopMEY\nWX4aoJKGwzlQSepgirssDYYBKmkwnAOVpI7GFZ8GqKQBcQ5UkjpIwsaRXYpkgEoajJE1oAaopOFw\nF16SOphciTTvKqZjgEoaDDtQSepoXPFpgEoaiMQT6SWps5HlpwEqaTjGNge6Ybk3JLk0yd1JHkly\nJMlNq1GYpPXnzA1F2ixD0KYDPQV8qKoeSHIx8LUkh6rqkRnXJmkdCVl7c6BVdQI40Tz+bpJHga1M\nvvpTkvoxoM6yranmQJNcBlwF3DuLYiStb2tuDvSMJBcBnwc+WFXPn+P1vUkOJzn83MmTfdYoaZ3Y\nMMUyBK3qSHIek/D8TFV94Vzvqar9VbWzqnb+xKZNfdYoaR0Ikw607TIEy+7CZ1Lpp4BHq+pjsy9J\n0no1tmvh23SgVwPvBd6R5MFmefeM65K0Dm1I+2UI2hyF/yrju0RV0shMzu8cV9R4JZKkwRhKZ9mW\nASppMEbWgBqgkoZhckPlcSXoUE6nkqRezwNNckuSZ5M8vGDst5McP9cB8SQ3Jzma5LEk17StV5IG\noeebiXwa2H2O8Y9X1Y5muXOy3VwB7AGubD7ziSQbl9uAASppEJLJzUTaLsupqnuAv2q5+WuB26rq\npap6HDgK7FruQwaopMGYsgPddOby8WbZ23Izv5nkoWYX/5JmbCvw1IL3HGvGluRBJEmDMeVpTCer\naueUm/g94N8C1fz8HeCfTrmOHzFAJQ3CahyFr6pnfrS95PeBO5qnx4FLF7x1WzO2JHfhJQ3GrO9I\nn2TLgqe/Dpw5Qn8Q2JPkgiSXA9uB+5Zbnx2opGHo+Rr3JJ8F3s5krvQY8BHg7Ul2MNmFfwL4AEBV\nHUlygMmN4k8BN1bV6eW2YYBKGoz0eNuNqrr+HMOfWuL9+4B902zDAJU0CJM50HlXMR0DVNJgGKCS\n1JG3s5OkDtyFl6Su1vrXGkvSLI3tdnYGqKRBcBe+sSHhwvOWvRPU4F30yrXx98u2iy6cdwm9+M73\nfzjvEnrxg1Mvz7uEFXu5aibrHVkDagcqaSjChpF9f6UBKmkQEtg4srtzGKCSBsODSJLUQXAOVJI6\nswOVpI5Glp8GqKRhCOO7w7sBKmkY4s1EJKmzccWnASppIFbjS+X6ZoBKGoxxxacBKmlARtaAGqCS\nhiIeRJKkLjyNSZJWwA5UkjoaV3waoJKGwhPpJakb50AlaQXsQCWpo3HFpwEqaUBG1oAuH6BJXgnc\nA1zQvP9zVfWRWRcmaX2ZzIGOK0HbzNm+BLyjqt4C7AB2J3nbbMuStB4l7Zfl15Vbkjyb5OEFY69L\ncijJt5qflyx47eYkR5M8luSaNvUuG6A18ULz9Lxmmc2XQktaxzLVPy18Gth91tiHgbuqajtwV/Oc\nJFcAe4Arm898IsnG5TbQ6qyBJBuTPAg8CxyqqnvbfE6SptFnB1pV9wB/ddbwtcCtzeNbgfcsGL+t\nql6qqseBo8Cu5bbRKkCr6nRV7QC2AbuS/OzZ70myN8nhJIdPnvx2m9VK0o+cmQNtuwCbzmROs+xt\nsZnNVXWiefw0sLl5vBV4asH7jjVjS5rqKHxV/XWSu5m0uA+f9dp+YD/Az//CTnfxJU2nZWe5wMmq\n2tl1c1VVSVaUVct2oElen+S1zeMLgXcB31zJRiXpXPrchV/EM0m2TLaVLUymJQGOA5cueN+2ZmxJ\nbXbhtwB3J3kIuJ/JHOgdU5UsSS30fBDpXA4CNzSPbwBuXzC+J8kFSS4HtgP3LbeyZXfhq+oh4Kpu\ntUpSO5PvROpxfclngbczmSs9BnwE+ChwIMn7gSeB6wCq6kiSA8AjwCngxqo6vdw2vBJJ0mCsoLP8\nMVV1/SIvvXOR9+8D9k2zDQNU0mCsuUs5JWm19NmBrgYDVNIg9D0HuhoMUEkDsaKj63NhgEoahpWd\n3zkXBqikwRhZfhqgkoZhMgc6rgg1QCUNxrji0wCVNCB+qZwkdTSy/DRAJQ3HyPLTAJU0ICNLUANU\n0iAEL+WUpG48kV6SuhtZfhqgkgZkZAlqgEoaCG8mIkmdOQfaWAvfa/yq8zfOu4ReXPLq8+ddQi9e\n+OGpeZfQiw/84YPzLmHFnvzO93pfZxjdHrwdqKQBGVmCGqCSBsM5UEnqyDlQSepoZPlpgEoaiBEe\nRTJAJQ2Gc6CS1EFwDlSSOhtZfhqgkgZkZAlqgEoaDOdAJakj50AlqaO+8zPJE8B3gdPAqarameR1\nwB8ClwFPANdV1Xe6rH9DP2VKUg8yxdLeL1XVjqra2Tz/MHBXVW0H7mqed2KAShqEM9+J1PafFbgW\nuLV5fCvwnq4rMkAlDUPznUhtl5YK+OMkX0uytxnbXFUnmsdPA5u7luwcqKTBmLKv3JTk8ILn+6tq\n/1nv+XtVdTzJTwKHknxz4YtVVUk6377YAJU0HNMl6MkF85rnVFXHm5/PJvkisAt4JsmWqjqRZAvw\nbNdy3YWXNBDTzIAun7RJXp3k4jOPgX8IPAwcBG5o3nYDcHvXiu1AJQ1Gz+eBbga+mMlKXwH8QVV9\nKcn9wIEk7weeBK7rugEDVNIg9H03u6r6C+At5xh/DnhnH9swQCUNx8iuRGo9B5pkY5KvJ7ljlgVJ\nWr9W6TzQ3kzTgd4EPAq8Zka1SFrnxnYtfKsONMk24FeAT862HEnr2Wyu5Jydtrvw/wH4l8DLi70h\nyd4kh5McPnny270UJ2kdmc2VSDO1bIAm+VXg2ar62lLvq6r9VbWzqnZu2vT63gqUtJ6MqwdtMwd6\nNfBrSd4NvBJ4TZL/UVX/eLalSVpPxvidSMt2oFV1c1Vtq6rLgD3AnxiekmZhXP2n54FKGpANI2tB\npwrQqvoK8JWZVCJJ48pPO1BJwzGy/DRAJQ3DkE5PassAlTQYQ7lEsy0DVNJwjCs/DVBJwzGy/DRA\nJQ2Hc6CS1MlwblPXlgEqaRDW5KWckqRzswOVNBhj60ANUEmD4RyoJHXhlUiS1M2QblPXlgEqaThG\nlqAGqKTBcA5UkjpyDlSSOhpZfhqgkgZkZAlqgEoajLHNgaaq+l9p8m3gyd5X/DdtAk7OeBuzthZ+\nB/D3GJrV+D3eVFWv73OFSb7EpPa2TlbV7j5rmNZMAnQ1JDlcVTvnXcdKrIXfAfw9hmat/B5j4M1E\nJKkjA1SSOhpzgO6fdwE9WAu/A/h7DM1a+T0Gb7RzoJI0b2PuQCVprgxQSerIAJWkjgxQSepoFJdy\nJnkzcC2wtRk6DhysqkfnV9X61fz32ArcW1UvLBjfXVVfml9l00myC6iquj/JFcBu4JtVdeecS1uR\nJP+tqt437zrWg8EfhU/yr4DrgduAY83wNmAPcFtVfXRetfUpyT+pqv867zqWk+SfAzcCjwI7gJuq\n6vbmtQeq6ufnWV9bST4C/DKTJuIQ8FbgbuBdwJerat8cy2stycGzh4BfAv4EoKp+bdWLWkfGEKD/\nG7iyqn541vj5wJGq2j6fyvqV5C+r6o3zrmM5Sb4B/GJVvZDkMuBzwH+vqt9N8vWqumquBbbU/B47\ngAuAp4FtVfV8kguZdNY/N9cCW0ryAPAI8EmgmAToZ5k0GFTVn86vurVvDLvwLwNv4MdvTrKleW00\nkjy02EvA5tWsZQU2nNltr6onkrwd+FySNzGum5GdqqrTwPeS/J+qeh6gql5MMqY/VzuBm4B/DfyL\nqnowyYsG5+oYQ4B+ELgrybeAp5qxNwJ/G/iNuVXVzWbgGuA7Z40H+LPVL6eTZ5LsqKoHAZpO9FeB\nW4C/O9/SpvKDJK+qqu8Bv3BmMMnfYkR/MVfVy8DHk/xR8/MZxvH/9Zow+H/RVfWlJD8N7OJvHkS6\nv+kgxuQO4KIz4bNQkq+sfjmdvA84tXCgqk4B70vyX+ZTUif/oKpegh+F0BnnATfMp6TuquoY8I+S\n/Arw/LzrWS8GPwcqSUPleaCS1JEBKkkdGaCS1JEBKkkd/X8kqL5lKyPt4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92782a5e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################         Fig. 13              #######################\n",
    "print(\"The Confusion matrix (true order vs predicted order) for sentence 4 is as follows:\")\n",
    "util.plot_confusion_matrix_dict(confusion_per_sentence[4],90, outside_label=\"None\")\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 2</font>: Assess Description (60 pts) \n",
    "\n",
    "We will mark the description along the following dimensions: \n",
    "\n",
    "* Clarity (10pts: very clear, 0pts: we can't figure out what you did, or you did nothing)\n",
    "* Creativity (25pts: we could not have come up with this, 0pts: Use only the provided model)\n",
    "* Substance (25pts: implemented complex state-of-the-art classifier, compared it to a simpler model, 0pts: Only use what is already there)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 2 is marked with ** __ points**.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Final mark</font>: Your solution to Assignment 3 is marked with ** __points**. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
